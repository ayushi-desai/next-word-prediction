{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2p_bqZM3WYu"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "1. Import Libraries\n",
        "2. Load Dataset\n",
        "3. Preprocessing and Exploring Text Data\n",
        "  \n",
        "  3.1 Text Cleaning\n",
        "  \n",
        "  3.2 Finding Word Count\n",
        "\n",
        "  3.3 Find and Replace Rare Words with \"Unknown\" Token\n",
        "\n",
        "4. Data Preparation\n",
        "\n",
        "  4.1 Prepare Sequences\n",
        "\n",
        "  4.2 Create Token-Integer Mappings\n",
        "\n",
        "  4.3 Split Data into Train and Validation Sets\n",
        "\n",
        "  4.4 Pad Sequences\n",
        "\n",
        "  4.5 Convert Text Sequences to Integer Sequences</br>\n",
        "  4.6 Implement GloVe Embeddings\n",
        "5. Model Building\n",
        "\n",
        "  5.1 Define Model Architecture\n",
        "  \n",
        "  5.2 Start Model Training\n",
        "6. Text Generation\n",
        "7. Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZoPOnsX8uPS"
      },
      "source": [
        "# 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z_CCxOEI4iZK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import re\n",
        "import random\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical \n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "from keras import backend as K \n",
        "K.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypl18CrLFmt6",
        "outputId": "a6ce13c6-d3c1-4559-dc72-b360b517de37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.66687293, 0.56621032, 0.81553805, ..., 0.56901873, 0.39138013,\n",
              "       0.73204124])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# reproducing same results\n",
        "SEED = 2019\n",
        "\n",
        "np.random.rand(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_5gPvXxWjru"
      },
      "source": [
        "# 2. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# open text file and read in data\n",
        "with open(\"Dailog-dataset.dialogs_dataset\", \"rb\") as f:\n",
        "  dialogs = pickle.load(f)"
      ],
      "metadata": {
        "id": "bNK5HMYflp8b"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81_SXWZlE6Zb",
        "outputId": "4292107b-9783-49aa-8c07-9346e1e14ee2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64776"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# number of text sequences\n",
        "len(dialogs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSyAzbttAqP2",
        "outputId": "f5b26d9a-ce77-4b35-dfd4-d45d66db5fb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Okay can you confirm the order',\n",
              " ' Could you slow down a little please?',\n",
              " 'no thank you just the pizza',\n",
              " 'I want to treat myself',\n",
              " \"Dang, there isn't anything cheaper than that? It seems expensive for a few miles\",\n",
              " ' Can you see if their regular espresso is available?',\n",
              " 'Great, thank you',\n",
              " ' And can you have them add basil to the whole pizza with roasted garlic on only half?',\n",
              " ' Glad to hear it',\n",
              " 'I want to bring the car in as soon as possible']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# print 10 random dialogs\n",
        "random.sample(dialogs, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGGTGRUDW9I3"
      },
      "source": [
        "# 3. Preprocessing and Exploring Text Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crvUl_ngM8sb"
      },
      "source": [
        "## 3.1 Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kUuUKZgUFhkl"
      },
      "outputs": [],
      "source": [
        "# text cleaning\n",
        "dialogs_clean = []\n",
        "\n",
        "for i in dialogs:\n",
        "  # remove everything except alphabets\n",
        "  i = re.sub(\"[^a-zA-Z' ]\", \"\", i)\n",
        "  # convert text to lowercase\n",
        "  i = i.lower()\n",
        "  # add cleaned text to the list\n",
        "  dialogs_clean.append(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYDzFQVvNA7_"
      },
      "source": [
        "\n",
        "## 3.2 Finding Word Count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "V1hrCYRp11UI"
      },
      "outputs": [],
      "source": [
        "# get list of all the words\n",
        "all_words = \" \".join(dialogs_clean).split()\n",
        "\n",
        "words_dict = {}\n",
        "\n",
        "# add word-count pair to the dictionary\n",
        "for word in all_words:   \n",
        "  # check if the word is already in dictionary \n",
        "  if word in words_dict:\n",
        "    # increment count of word by 1 \n",
        "    words_dict[word] = words_dict[word] + 1\n",
        "  else:\n",
        "    # add the word to dictionary with count 1 \n",
        "    words_dict[word] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gNxSGPubWaqA"
      },
      "outputs": [],
      "source": [
        "# prepare a dataframe\n",
        "words_df = pd.DataFrame({'word':list(words_dict.keys()), 'count':list(words_dict.values())})\n",
        "\n",
        "# sort words by their count in increasing order\n",
        "words_df = words_df.sort_values(by = ['count'])\n",
        "\n",
        "# reset dataframe index\n",
        "words_df.reset_index(inplace = True, drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVPbPsSWo-Ak",
        "outputId": "93444b43-46f4-4524-f9f6-852abf0c3e4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11147"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# vocabulary size\n",
        "len(words_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JTwmmOiEXBHt",
        "outputId": "5807edec-f563-4144-eefd-b7d10007a1f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          word  count\n",
              "0  uppermiddle      1\n",
              "1       shoots      1\n",
              "2        geesh      1\n",
              "3       andrea      1\n",
              "4      precice      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f00766e3-e038-4f0a-81b2-a3e9e400f5ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>uppermiddle</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>shoots</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>geesh</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>andrea</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>precice</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f00766e3-e038-4f0a-81b2-a3e9e400f5ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f00766e3-e038-4f0a-81b2-a3e9e400f5ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f00766e3-e038-4f0a-81b2-a3e9e400f5ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "words_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EWJEto8TMPiq",
        "outputId": "312c203a-36e6-4458-8824-8fa87080fc62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      word  count\n",
              "11142  you  11909\n",
              "11143    a  13380\n",
              "11144   to  14000\n",
              "11145  the  15406\n",
              "11146    i  19654"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e52d64a-8388-48b0-a82c-c702ef2114a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11142</th>\n",
              "      <td>you</td>\n",
              "      <td>11909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11143</th>\n",
              "      <td>a</td>\n",
              "      <td>13380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11144</th>\n",
              "      <td>to</td>\n",
              "      <td>14000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11145</th>\n",
              "      <td>the</td>\n",
              "      <td>15406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11146</th>\n",
              "      <td>i</td>\n",
              "      <td>19654</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e52d64a-8388-48b0-a82c-c702ef2114a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e52d64a-8388-48b0-a82c-c702ef2114a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e52d64a-8388-48b0-a82c-c702ef2114a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "words_df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTcWd-pYFRob"
      },
      "source": [
        "## 3.3 Find and Replace Rare Words with \"Unknown\" Token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1iC4ztG3XIP3"
      },
      "outputs": [],
      "source": [
        "# user specified threshold value\n",
        "rare_thresh = 2\n",
        "\n",
        "# get percentage of rare words in the vocabulary\n",
        "rare_words_count = len(words_df[words_df['count'] < rare_thresh]['word'])\n",
        "total_words = len(words_df) \n",
        "rare_dist = rare_words_count / total_words\n",
        "\n",
        "# coverage percentage of rare words in the corpus\n",
        "rare_cover = words_df[words_df['count'] < rare_thresh]['count'].sum()/words_df['count'].sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "helYHQ4BXNK9",
        "outputId": "02af2f40-1831-4a44-fd1b-a6c1269c7026"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rare words distribution in the vocabulary: 47.98\n",
            "Rare words coverage in the corpus: 1.12\n"
          ]
        }
      ],
      "source": [
        "print(f\"Rare words distribution in the vocabulary: {rare_dist*100:.2f}\")\n",
        "print(f\"Rare words coverage in the corpus: {rare_cover*100:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yJhbRQllXQJk"
      },
      "outputs": [],
      "source": [
        "# extract rare words in a list\n",
        "rare_words = words_df[words_df['count'] < rare_thresh]['word'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "178uBVztqTDa"
      },
      "source": [
        "Replace the rare words/tokens in the dataset with a special token known as the unknown token (\"\\<unk\\>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5tSChzyoOJT",
        "outputId": "5ae8d2c6-49b2-48bc-a893-7eb1e20e62de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day|book|\n"
          ]
        }
      ],
      "source": [
        "## example\n",
        "# specify rare words\n",
        "r_words = [\"day\", \"book\"]\n",
        "\n",
        "# build pattern\n",
        "pattern = \"\"\n",
        "for i in r_words:\n",
        "  pattern+= \"{}|\".format(i)\n",
        "\n",
        "print(pattern)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZAMqmwPowZj",
        "outputId": "9def0ce4-ad99-44d8-addd-9100229ff0dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day|book\n"
          ]
        }
      ],
      "source": [
        "# removing the last element which is \"|\"\n",
        "pattern = pattern[:-1]\n",
        "print(pattern)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV1K1ibbo3XI",
        "outputId": "78f4c0ef-67a7-4ff7-c447-264025ecad50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it has been a long  <unk> \n",
            "this  <unk>  is a must read\n"
          ]
        }
      ],
      "source": [
        "# replace the rare words with the <unk> token\n",
        "sents = [\"it has been a long day\", \"this book is a must read\"]\n",
        "\n",
        "for d in sents:\n",
        "  text = re.sub(pattern, \" <unk> \", d)\n",
        "  print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hEn-L1_8YBjl"
      },
      "outputs": [],
      "source": [
        "# create a text pattern from the rare words, like \"word1 | word2 | word3...\"\n",
        "pattern = \"\"\n",
        "for i in rare_words:\n",
        "  pattern+= \" {} |\".format(i)\n",
        "\n",
        "# removing the last element which is \"|\"\n",
        "pattern = pattern[:-1]\n",
        "\n",
        "# empty list \n",
        "dialogs_clean_v2 = []\n",
        "\n",
        "# replace the rare words with the <unk> token\n",
        "#for d in tqdm_notebook(dialogs_clean):\n",
        "for d in dialogs_clean:\n",
        "  text = re.sub(pattern, \" <unk> \", d)\n",
        "  dialogs_clean_v2.append(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FMh9IVnQdyGE"
      },
      "outputs": [],
      "source": [
        "dialogs_clean_v2 = dialogs_clean[:12000]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dialogs_clean_v2[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Skg_W9Aaj4EK",
        "outputId": "5c194183-c05c-41ca-d2ad-c54b5dc44e28"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"hi i'm looking to book a table for korean fod\",\n",
              " 'somewhere in southern nyc maybe the east village',\n",
              " \" we don't want to sit at the bar but anywhere else is fine\",\n",
              " 'what times are available',\n",
              " \"yikes we can't do those times\",\n",
              " 'let me check',\n",
              " \"great let's book that\",\n",
              " \"no that's it just book\",\n",
              " 'hi i would like to see if the movie what men want is playing here',\n",
              " 'yes for me and a friend so two tickets please']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waTukoy1AbVT"
      },
      "source": [
        "# 4. Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SvIJQ0brBWW"
      },
      "source": [
        "## 4.1 Prepare Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "H5BYGcwBF7hX",
        "outputId": "ae4cd0f9-3cd0-4cad-9cea-0206ba8142d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAW/klEQVR4nO3df5Bd5X3f8fenwmBZmyJhObdUUrtKojhDUOLCBsg4yeyaBi+QiciMw8CQWHLJbJKCS4oyAdzpkDphqqQh1J46ZDZBIzHjsCaYBA0hwariW8pMwCCCWQR2WGNhtCNLJRJK1iZ21/72j/sovtnuau+ec3+e5/Oa0ey9z3nOOc9XZ/W5R+ece44iAjMzy8M/6/UAzMysexz6ZmYZceibmWXEoW9mlhGHvplZRs7q9QDOZP369TE8PFx4/q997WusWbOmfQPqkarUAa6lX1WllqrUAeVqOXjw4BsR8a7FpvV16A8PD/Pss88Wnr9erzM6Otq+AfVIVeoA19KvqlJLVeqAcrVIem2paT68Y2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWkb7+Ru6gGr79z9q6vD3j1fhauZn1nvf0zcwy4tA3M8uIQ9/MLCMOfTOzjCwb+pJ2Szou6cUF7R+W9AVJhyT9dlP7HZJmJH1R0vub2sdT24yk29tbhpmZtaKVq3f2AP8DuP90g6QxYBvwwxHxDUnfndovAK4DfhD4l8D/lPT9abZPAD8JHAGekbQvIl5qVyFmZra8ZUM/Ip6QNLyg+ZeBXRHxjdTneGrfBkyl9i9LmgEuSdNmIuJVAElTqa9D38ysi4oe0/9+4MclPS3pf0n6kdS+AXi9qd+R1LZUu5mZdVHRL2edBZwHXAb8CPCgpO9px4AkTQATALVajXq9XnhZc3NzpeYvaufW+bYur1d1dIJr6U9VqaUqdUDnaika+keAhyMigM9J+jawHpgFNjX125jaOEP7PxERk8AkwMjISJR53mWvnpe5owPfyPVzP/uPa+k/VakDOldL0cM7fwqMAaQTtWcDbwD7gOsknSNpM7AF+BzwDLBF0mZJZ9M42buv7ODNzGxllt3Tl/QAMAqsl3QEuBPYDexOl3F+E9ie9voPSXqQxgnaeeCmiPhWWs7NwOPAKmB3RBzqQD1mZnYGrVy9c/0Sk35uif53AXct0v4Y8NiKRmdmZm3lb+SamWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlpGid9m0LpqePdXynTsP77q6w6Mxs0HmPX0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4wsG/qSdks6np6StXDaTkkhaX16L0kflzQj6QVJFzX13S7plfRne3vLMDOzVrSyp78HGF/YKGkTcAXwlabmK2k8F3cLMAHcm/qeR+Mxi5cClwB3SlpXZuBmZrZyy4Z+RDwBnFhk0j3ArwHR1LYNuD8angLWSjofeD+wPyJORMRJYD+LfJCYmVlnFfpylqRtwGxEfF5S86QNwOtN74+ktqXaF1v2BI3/JVCr1ajX60WGCMDc3Fyp+YvauXW+rcurrW59mb2odyV6tU06wbX0n6rUAZ2rZcWhL+kdwEdoHNppu4iYBCYBRkZGYnR0tPCy6vU6ZeYvqtVvz7Zq59Z57p5ubVMdvmG0retut15tk05wLf2nKnVA52opcvXO9wKbgc9LOgxsBJ6T9C+AWWBTU9+NqW2pdjMz66IVh35ETEfEd0fEcEQM0zhUc1FEfBXYB3wwXcVzGXAqIo4CjwNXSFqXTuBekdrMzKyLWrlk8wHgr4B3Szoi6cYzdH8MeBWYAf4A+PcAEXEC+A3gmfTno6nNzMy6aNkDxRFx/TLTh5teB3DTEv12A7tXOD4zM2sjfyPXzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLSKG7bFr/Gm7xZm+Hd13d4ZGYWT/ynr6ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHom5llpJUnZ+2WdFzSi01t/03SFyS9IOlPJK1tmnaHpBlJX5T0/qb28dQ2I+n29pdiZmbLaWVPfw8wvqBtP3BhRPwQ8DfAHQCSLgCuA34wzfN7klZJWgV8ArgSuAC4PvU1M7MuWjb0I+IJ4MSCts9ExHx6+xSwMb3eBkxFxDci4ss0npV7SfozExGvRsQ3ganU18zMuqgdt2H4d8Cn0usNND4ETjuS2gBeX9B+6WILkzQBTADUajXq9Xrhgc3NzZWav6idW+eX77QCtdXtX2Yv/l6gd9ukE1xL/6lKHdC5WkqFvqT/BMwDn2zPcCAiJoFJgJGRkRgdHS28rHq9Tpn5i9rR4v1vWrVz6zx3T7f3NkmHbxht6/Ja1att0gmupf9UpQ7oXC2Fk0TSDuCngMsjIlLzLLCpqdvG1MYZ2s3MrEsKXbIpaRz4NeCnI+LrTZP2AddJOkfSZmAL8DngGWCLpM2SzqZxsndfuaGbmdlKLbunL+kBYBRYL+kIcCeNq3XOAfZLAngqIn4pIg5JehB4icZhn5si4ltpOTcDjwOrgN0RcagD9ZiZ2RksG/oRcf0izfedof9dwF2LtD8GPLai0ZmZWVv5ISqZ8sNWzPLk2zCYmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHvplZRpYNfUm7JR2X9GJT23mS9kt6Jf1cl9ol6eOSZiS9IOmipnm2p/6vSNremXLMzOxMWtnT3wOML2i7HTgQEVuAA+k9wJU0nou7BZgA7oXGhwSNxyxeClwC3Hn6g8LMzLpn2dCPiCeAEwuatwF70+u9wDVN7fdHw1PAWknnA+8H9kfEiYg4Cezn//8gMTOzDlNELN9JGgYejYgL0/s3I2Jtei3gZESslfQosCsinkzTDgC30Xiw+tsj4jdT+38G3oqI31lkXRM0/pdArVa7eGpqqnBxc3NzDA0NFZ6/qOnZU21dXm01HHurrYtsu60bzm2pX6+2SSe4lv5TlTqgXC1jY2MHI2JksWmln5EbESFp+U+O1pc3CUwCjIyMxOjoaOFl1et1ysxf1I4Wnz/bqp1b57l7ur8fZ3z4htGW+vVqm3SCa+k/VakDOldL0at3jqXDNqSfx1P7LLCpqd/G1LZUu5mZdVHR0N8HnL4CZzvwSFP7B9NVPJcBpyLiKPA4cIWkdekE7hWpzczMumjZYwaSHqBxTH69pCM0rsLZBTwo6UbgNeDa1P0x4CpgBvg68CGAiDgh6TeAZ1K/j0bEwpPDZmbWYcuGfkRcv8SkyxfpG8BNSyxnN7B7RaMzM7O28jdyzcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8tIfz+DzwbGcIuPiNwzvqbDIzGzM/GevplZRkqFvqT/KOmQpBclPSDp7ZI2S3pa0oykT0k6O/U9J72fSdOH21GAmZm1rnDoS9oA/AdgJCIuBFYB1wG/BdwTEd8HnARuTLPcCJxM7fekfmZm1kVlD++cBayWdBbwDuAo8D7goTR9L3BNer0tvSdNv1ySSq7fzMxWQI3H2hacWboFuAt4C/gMcAvwVNqbR9Im4M8j4kJJLwLjEXEkTfsScGlEvLFgmRPABECtVrt4amqq8Pjm5uYYGhoqPH9R07On2rq82mo49lZbF9kzm89d1ZNt0gm9+v3qhKrUUpU6oFwtY2NjByNiZLFpha/ekbSOxt77ZuBN4I+B8aLLOy0iJoFJgJGRkRgdHS28rHq9Tpn5i9rR4pUsrdq5dZ67p6txodWe8TU92Sad0Kvfr06oSi1VqQM6V0uZwzv/FvhyRPyfiPi/wMPAe4G16XAPwEZgNr2eBTYBpOnnAn9bYv1mZrZCZUL/K8Blkt6Rjs1fDrwEfBb4QOqzHXgkvd6X3pOm/2WUObZkZmYrVjj0I+JpGidknwOm07ImgduAWyXNAO8E7kuz3Ae8M7XfCtxeYtxmZlZAqQPFEXEncOeC5leBSxbp+w/Az5ZZn5mZleNv5JqZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGqnFDFxsY07OnWro30eFdV3dhNGb58Z6+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZaRU6EtaK+khSV+Q9LKkH5V0nqT9kl5JP9elvpL0cUkzkl6QdFF7SjAzs1aV3dP/GPAXEfEDwA8DL9N4ItaBiNgCHOA7T8i6EtiS/kwA95Zct5mZrVDh0Jd0LvATpMchRsQ3I+JNYBuwN3XbC1yTXm8D7o+Gp2g8QP38wiM3M7MVU9Fnk0t6D41n4r5EYy//IHALMBsRa1MfAScjYq2kR4FdEfFkmnYAuC0inl2w3Aka/xOgVqtdPDU1VWh8AHNzcwwNDRWev6jp2VNtXV5tNRx7q62L7JlWa9m64dzOD6akXv1+dUJVaqlKHVCulrGxsYMRMbLYtDL33jkLuAj4cEQ8LeljLHjYeUSEpBV9qkTEJI0PE0ZGRmJ0dLTwAOv1OmXmL6qVe8usxM6t89w9XY3bJLVay+EbRjs/mJJ69fvVCVWppSp1QOdqKXNM/whwJCKeTu8fovEhcOz0YZv083iaPgtsapp/Y2ozM7MuKRz6EfFV4HVJ705Nl9M41LMP2J7atgOPpNf7gA+mq3guA05FxNGi6zczs5Ure8zgw8AnJZ0NvAp8iMYHyYOSbgReA65NfR8DrgJmgK+nvmZm1kWlQj8ingcWO1lw+SJ9A7ipzPrMzKycapwdtMoZbvFkuB+2YrYyvg2DmVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZaR06EtaJemvJT2a3m+W9LSkGUmfSk/VQtI56f1Mmj5cdt1mZrYy7djTvwV4uen9bwH3RMT3ASeBG1P7jcDJ1H5P6mdmZl1UKvQlbQSuBv4wvRfwPuCh1GUvcE16vS29J02/PPU3M7MuUePRtQVnlh4C/ivwXcCvAjuAp9LePJI2AX8eERdKehEYj4gjadqXgEsj4o0Fy5wAJgBqtdrFU1NThcc3NzfH0NBQ4fmLmp491dbl1VbDsbfausieaXctWzec276FrVCvfr86oSq1VKUOKFfL2NjYwYhY7PnlxZ+RK+mngOMRcVDSaNHlLBQRk8AkwMjISIyOFl90vV6nzPxF7Wjx+a6t2rl1nrunq/E443bXcviG0bYta6V69fvVCVWppSp1QOdqKfOv773AT0u6Cng78M+BjwFrJZ0VEfPARmA29Z8FNgFHJJ0FnAv8bYn1m5nZChUO/Yi4A7gDIO3p/2pE3CDpj4EPAFPAduCRNMu+9P6v0vS/jDLHlsyA4RX8r+rwrqs7OBKzwdCJ6/RvA26VNAO8E7gvtd8HvDO13wrc3oF1m5nZGbTl4GpE1IF6ev0qcMkiff4B+Nl2rM/MzIrxN3LNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4hD38wsIw59M7OMVOMuXmYtaPWWDb5dg1WZ9/TNzDLi0Dczy4hD38wsIw59M7OMOPTNzDLi0Dczy4gv2TRboNVLO/eMr+nwSMzar/CevqRNkj4r6SVJhyTdktrPk7Rf0ivp57rULkkflzQj6QVJF7WrCDMza02ZwzvzwM6IuAC4DLhJ0gU0HoN4ICK2AAf4zmMRrwS2pD8TwL0l1m1mZgUUDv2IOBoRz6XXfw+8DGwAtgF7U7e9wDXp9Tbg/mh4Clgr6fzCIzczsxVTRJRfiDQMPAFcCHwlItamdgEnI2KtpEeBXRHxZJp2ALgtIp5dsKwJGv8ToFarXTw1NVV4XHNzcwwNDRWev6jp2VNtXV5tNRx7q62L7Jkq1bL53FU9+f3qhF79W2m3qtQB5WoZGxs7GBEji00rfSJX0hDwaeBXIuLvGjnfEBEhaUWfKhExCUwCjIyMxOjoaOGx1et1ysxf1I4WTwS2aufWee6ersY598rV8uTXlu03CPfy6dW/lXarSh3QuVpKXbIp6W00Av+TEfFwaj52+rBN+nk8tc8Cm5pm35jazMysS8pcvSPgPuDliPjdpkn7gO3p9Xbgkab2D6areC4DTkXE0aLrNzOzlSvz/+z3Aj8PTEt6PrV9BNgFPCjpRuA14No07THgKmAG+DrwoRLrNjOzAgqHfjohqyUmX75I/wBuKro+MzMrz7dhMDPLiEPfzCwjDn0zs4w49M3MMuLQNzPLSDW+GmnWx1q9VXOrBuEbvta/vKdvZpYRh76ZWUYc+mZmGXHom5llxCdyzQZMqyeGfcLXFuM9fTOzjHhP36yiVnKp6J7xNR0cifUT7+mbmWXEe/pmxvTsqbY+5tPnE/qXQ9/M2s4nm/tX10Nf0jjwMWAV8IcRsavbYzCz/uAPh+7rauhLWgV8AvhJ4AjwjKR9EfFSN8dRVLvvoWJmrWn1397OrfMtHabK+UOk23v6lwAzEfEqgKQpYBswEKFvZtUwCDtwnbqiSo1H13aHpA8A4xHxC+n9zwOXRsTNTX0mgIn09t3AF0uscj3wRon5+0VV6gDX0q+qUktV6oBytfzriHjXYhP67kRuREwCk+1YlqRnI2KkHcvqparUAa6lX1WllqrUAZ2rpdvX6c8Cm5reb0xtZmbWBd0O/WeALZI2SzobuA7Y1+UxmJllq6uHdyJiXtLNwOM0LtncHRGHOrjKthwm6gNVqQNcS7+qSi1VqQM6VEtXT+SamVlv+d47ZmYZceibmWWkkqEvaVzSFyXNSLq91+MpQ9JhSdOSnpf0bK/HsxKSdks6LunFprbzJO2X9Er6ua6XY2zVErX8uqTZtG2el3RVL8fYCkmbJH1W0kuSDkm6JbUP3HY5Qy2DuF3eLulzkj6favkvqX2zpKdTln0qXQBTbl1VO6afbvXwNzTd6gG4flBu9bCQpMPASEQM3BdOJP0EMAfcHxEXprbfBk5ExK70gbwuIm7r5ThbsUQtvw7MRcTv9HJsKyHpfOD8iHhO0ncBB4FrgB0M2HY5Qy3XMnjbRcCaiJiT9DbgSeAW4Fbg4YiYkvT7wOcj4t4y66rinv4/3uohIr4JnL7Vg3VZRDwBnFjQvA3Ym17vpfGPtO8tUcvAiYijEfFcev33wMvABgZwu5yhloETDXPp7dvSnwDeBzyU2tuyXaoY+huA15veH2FAfxGSAD4j6WC6RcWgq0XE0fT6q0Ctl4Npg5slvZAO//T9IZFmkoaBfwM8zYBvlwW1wABuF0mrJD0PHAf2A18C3oyI+dSlLVlWxdCvmh+LiIuAK4Gb0mGGSojGscVBPr54L/C9wHuAo8DdvR1O6yQNAZ8GfiUi/q552qBtl0VqGcjtEhHfioj30LhTwSXAD3RiPVUM/Urd6iEiZtPP48Cf0PhlGGTH0rHY08dkj/d4PIVFxLH0D/XbwB8wINsmHTP+NPDJiHg4NQ/kdlmslkHdLqdFxJvAZ4EfBdZKOv0l2rZkWRVDvzK3epC0Jp2gQtIa4ArgxTPP1ff2AdvT6+3AIz0cSymnQzL5GQZg26QThvcBL0fE7zZNGrjtslQtA7pd3iVpbXq9msaFKC/TCP8PpG5t2S6Vu3oHIF2i9d/5zq0e7urxkAqR9D009u6hccuMPxqkWiQ9AIzSuEXsMeBO4E+BB4F/BbwGXBsRfX+CdIlaRmkcQgjgMPCLTcfF+5KkHwP+NzANfDs1f4TGsfCB2i5nqOV6Bm+7/BCNE7WraOyMPxgRH00ZMAWcB/w18HMR8Y1S66pi6JuZ2eKqeHjHzMyW4NA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ9/MLCP/Dw6yz8yXvrv4AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# capture length of all the sequences\n",
        "text_word_count = []\n",
        "for i in dialogs_clean_v2:\n",
        "  text_word_count.append(len(i.split()))\n",
        "        \n",
        "# plot the sequence lengths\n",
        "pd.Series(text_word_count).hist(bins = 30,range=(0,30))\n",
        "print(len(text_word_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uw8F6bfwjBeo"
      },
      "outputs": [],
      "source": [
        "# function to create sequences of equal length\n",
        "def create_seq1(text, seq_len = 5):\n",
        "      \n",
        "  sequences = []    \n",
        "  temp = 0\n",
        "  seq_len1 = 5\n",
        "  if len(text.split()) > seq_len:\n",
        "    for i in range(0, round(len(text.split())/seq_len)):\n",
        "      # select sequence of tokens\n",
        "      seq = text.split()[temp:seq_len1]\n",
        "      temp = seq_len1\n",
        "      seq_len1 = seq_len + temp\n",
        "      \n",
        "      if len(seq) > 0:\n",
        "        # append sequence to the list\n",
        "        sequences.append(\" \".join(seq))\n",
        "\n",
        "    return sequences\n",
        "\n",
        "  else:\n",
        "    \n",
        "    return [text]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create sequences of equal length\n",
        "def create_seq(text, seq_len = 5):\n",
        "      \n",
        "  sequences = []    \n",
        "  \n",
        "  if len(text.split()) > seq_len:\n",
        "    for i in range(seq_len, len(text.split())):\n",
        "      # select sequence of tokens\n",
        "      seq = text.split()[i-seq_len:i+1]\n",
        "      # append sequence to the list\n",
        "      sequences.append(\" \".join(seq))\n",
        "\n",
        "    return sequences\n",
        "\n",
        "  else:\n",
        "    \n",
        "    return [text]"
      ],
      "metadata": {
        "id": "QuiaxDXww5H_"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0psJCgo9QtH",
        "outputId": "cd880eae-143a-4030-b24e-f154dfb196cd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[\"hi i'm looking to book a\",\n",
              "  \"i'm looking to book a table\",\n",
              "  'looking to book a table for',\n",
              "  'to book a table for korean',\n",
              "  'book a table for korean fod'],\n",
              " ['somewhere in southern nyc maybe the',\n",
              "  'in southern nyc maybe the east',\n",
              "  'southern nyc maybe the east village'],\n",
              " [\"we don't want to sit at\",\n",
              "  \"don't want to sit at the\",\n",
              "  'want to sit at the bar',\n",
              "  'to sit at the bar but',\n",
              "  'sit at the bar but anywhere',\n",
              "  'at the bar but anywhere else',\n",
              "  'the bar but anywhere else is',\n",
              "  'bar but anywhere else is fine'],\n",
              " ['what times are available'],\n",
              " [\"yikes we can't do those times\"],\n",
              " ['let me check'],\n",
              " [\"great let's book that\"],\n",
              " [\"no that's it just book\"],\n",
              " ['hi i would like to see',\n",
              "  'i would like to see if',\n",
              "  'would like to see if the',\n",
              "  'like to see if the movie',\n",
              "  'to see if the movie what',\n",
              "  'see if the movie what men',\n",
              "  'if the movie what men want',\n",
              "  'the movie what men want is',\n",
              "  'movie what men want is playing',\n",
              "  'what men want is playing here'],\n",
              " ['yes for me and a friend',\n",
              "  'for me and a friend so',\n",
              "  'me and a friend so two',\n",
              "  'and a friend so two tickets',\n",
              "  'a friend so two tickets please']]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# create sequences of equal length\n",
        "seqs = [create_seq(i) for i in dialogs_clean_v2 if len(i) < 100 and len(i) > 1]\n",
        "#seqs = [i for i in dialogs_clean_v2 if len(i) < 80]\n",
        "seqs[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0_sqNUB1p86p"
      },
      "outputs": [],
      "source": [
        "# merge list-of-lists into a single list\n",
        "corpus = sum(seqs, [])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwmBsxuqxPRq",
        "outputId": "9662e49c-3a8e-4641-d557-0ab76d301fb8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"hi i'm looking to book a\",\n",
              " \"i'm looking to book a table\",\n",
              " 'looking to book a table for',\n",
              " 'to book a table for korean',\n",
              " 'book a table for korean fod',\n",
              " 'somewhere in southern nyc maybe the',\n",
              " 'in southern nyc maybe the east',\n",
              " 'southern nyc maybe the east village',\n",
              " \"we don't want to sit at\",\n",
              " \"don't want to sit at the\",\n",
              " 'want to sit at the bar',\n",
              " 'to sit at the bar but',\n",
              " 'sit at the bar but anywhere',\n",
              " 'at the bar but anywhere else',\n",
              " 'the bar but anywhere else is',\n",
              " 'bar but anywhere else is fine',\n",
              " 'what times are available',\n",
              " \"yikes we can't do those times\",\n",
              " 'let me check',\n",
              " \"great let's book that\"]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "corpus[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_1Lazko0ncT"
      },
      "source": [
        " **4.2 Create Token-Integer Mappings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ycKTOMtn3IHb"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGudI_YR3NVa",
        "outputId": "cc2b8dd6-3716-4e63-d964-8749fe1ee3ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4551"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "total_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i87lF6O70zSC"
      },
      "source": [
        "**4.3 Generates a list of n-gram sequences and list of n-gram sequences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hdQyfvD24Yzg"
      },
      "outputs": [],
      "source": [
        "#Create n_gram_seqs\n",
        "def n_gram_seqs(corpus, tokenizer):\n",
        "    \"\"\"\n",
        "    Generates a list of n-gram sequences\n",
        "    \n",
        "    Args:\n",
        "        corpus (list of string): lines of texts to generate n-grams for\n",
        "        tokenizer (object): an instance of the Tokenizer class containing the word-index dictionary\n",
        "    \n",
        "    Returns:\n",
        "        input_sequences (list of int): the n-gram sequences for each line in the corpus\n",
        "    \"\"\"\n",
        "    input_sequences = []\n",
        "    output_sequences = []\n",
        "    ### START CODE HERE\n",
        "    for line in corpus:\n",
        "      token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "      \n",
        "      for i in range(1, len(token_list)):\n",
        "        n_gram_seqs= token_list[:i]\n",
        "        #print(n_gram_seqs)\n",
        "        input_sequences.append(n_gram_seqs)\n",
        "        output_sequences.append(token_list[i:i+1])\n",
        "        \n",
        "    ### END CODE HERE\n",
        "    \n",
        "    return input_sequences, output_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WGyZvGA4iJK",
        "outputId": "619b3624-a179-4890-cbb6-a6ae7dc2e399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_grams of input_sequences length: 166917\n",
            "maximum length of sequences : 5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[115],\n",
              " [115, 61],\n",
              " [115, 61, 123],\n",
              " [115, 61, 123, 1],\n",
              " [115, 61, 123, 1, 52],\n",
              " [61],\n",
              " [61, 123],\n",
              " [61, 123, 1],\n",
              " [61, 123, 1, 52],\n",
              " [61, 123, 1, 52, 3]]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Apply the n_gram_seqs transformation to the whole corpus\n",
        "input_sequences, output_sequences = n_gram_seqs(corpus, tokenizer)\n",
        "\n",
        "# Save max length \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "print(f\"n_grams of input_sequences length: {len(input_sequences)}\")\n",
        "print(f\"maximum length of sequences : {max_sequence_len}\")\n",
        "input_sequences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1bvMXPF-atc",
        "outputId": "9fe45a37-2df2-4328-dcb7-417fab2acc74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[61], [123], [1], [52], [3], [123], [1], [52], [3], [102]]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "output_sequences[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWdt2Yzd0uFG"
      },
      "source": [
        "**4.4 Create Token-Integer Mappings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "u7oNbNAR4k_i"
      },
      "outputs": [],
      "source": [
        "def pad_seqs(input_sequences, maxlen):\n",
        "    \"\"\"\n",
        "    Pads tokenized sequences to same length\n",
        "    \n",
        "    Args:\n",
        "        input_sequences: tokenized sequences to pad\n",
        "        maxlen: maximum length of sequences\n",
        "    \n",
        "    Returns:\n",
        "        padded_sequences: tokenized sequences padded to  same length\n",
        "    \"\"\"\n",
        "\n",
        "    post_pad_sequence = pad_sequences(input_sequences, maxlen=maxlen, padding='pre')\n",
        "    return post_pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br1dRGoP4upC",
        "outputId": "e37a5a88-13f1-4396-cfef-d43c42fa5710"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padded corpus has shape: (166917, 5)\n"
          ]
        }
      ],
      "source": [
        "# Pad the whole corpus\n",
        "pad_sequence = pad_seqs(input_sequences, max_sequence_len)\n",
        "\n",
        "print(f\"padded corpus has shape: {pad_sequence.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNFLZSx9l2f-",
        "outputId": "253954f8-dcd5-4d68-872f-9d0d0b9efa00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0, 115],\n",
              "       [  0,   0,   0, 115,  61],\n",
              "       [  0,   0, 115,  61, 123],\n",
              "       ...,\n",
              "       [  0,   0,  29,  23,   9],\n",
              "       [  0,  29,  23,   9,   6],\n",
              "       [ 29,  23,   9,   6,  62]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Fuk3GeAa4xIa"
      },
      "outputs": [],
      "source": [
        "def features_and_labels(pad_sequence, labels, total_words):\n",
        "\n",
        "    #features = pre_pad_sequence[:,:-1]\n",
        "    one_hot_labels = to_categorical(labels, num_classes=total_words)\n",
        "\n",
        "    return pad_sequence, one_hot_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4gxDZzd42P8",
        "outputId": "3ef1cbb5-083c-4b56-c2af-5343e8d21371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features have shape: (166917, 5)\n",
            "labels have shape: (166917, 4551)\n"
          ]
        }
      ],
      "source": [
        "# Split the whole corpus\n",
        "features, labels = features_and_labels(pad_sequence, output_sequences, total_words)\n",
        "\n",
        "print(f\"features have shape: {features.shape}\")\n",
        "print(f\"labels have shape: {labels.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz1wUvgzlwl8",
        "outputId": "9995e1e5-2fb4-4b60-eaba-45f0dd9bb12e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0, 115],\n",
              "       [  0,   0,   0, 115,  61],\n",
              "       [  0,   0, 115,  61, 123],\n",
              "       ...,\n",
              "       [  0,   0,  29,  23,   9],\n",
              "       [  0,  29,  23,   9,   6],\n",
              "       [ 29,  23,   9,   6,  62]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "post_pad_sequence = []\n",
        "pre_pad_sequence = []\n",
        "#seqs = []\n",
        "corpus = []\n",
        "features"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implement Glove to get better accuracy**"
      ],
      "metadata": {
        "id": "bmYz0WBQZb35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define path to file containing the embeddings\n",
        "GLOVE_FILE = './glove.6B.100d.txt'\n",
        "\n",
        "# Initialize an empty embeddings index dictionary\n",
        "GLOVE_EMBEDDINGS = {}\n",
        "\n",
        "# Read file and fill GLOVE_EMBEDDINGS with its contents\n",
        "with open(GLOVE_FILE) as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        GLOVE_EMBEDDINGS[word] = coefs"
      ],
      "metadata": {
        "id": "AmSN2V_HDEWK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 100\n",
        "word_index = tokenizer.word_index\n",
        "# Initialize empty numpy array with the appropriate size\n",
        "EMBEDDINGS_MATRIX = np.zeros((total_words+1, EMBEDDING_DIM))\n",
        "\n",
        "# Iterate all of the words in the vocabulary\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = GLOVE_EMBEDDINGS.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        EMBEDDINGS_MATRIX[i] = embedding_vector"
      ],
      "metadata": {
        "id": "qLglCzKUD0Hr"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7YLFIwX1M0a"
      },
      "source": [
        "# **5.1 Define Model Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "uHbLbl3n44xB"
      },
      "outputs": [],
      "source": [
        "from keras import regularizers\n",
        "from keras.regularizers import l2\n",
        "def create_model(total_words, embedding_dim, embeddings_matrix,  max_sequence_len):\n",
        "  model = Sequential()\n",
        "  #model.add(Embedding(total_words, 100, input_length=max_sequence_len))\n",
        "\n",
        "  model.add(Embedding(total_words+1, embedding_dim, input_length=max_sequence_len, weights=[embeddings_matrix]))\n",
        "  #model.add(LSTM(units=128 , return_sequences = True , recurrent_dropout = 0.15 , dropout = 0.15))\n",
        "  #model.add(tf.keras.layers.Dropout(.2))\n",
        "  model.add(Bidirectional(LSTM(units=128)))\n",
        "\n",
        "  model.add(Dense(total_words, activation='softmax'))\n",
        "  learning_rate = 0.001\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "  # Compile the model\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer= opt,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  model.summary()\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOaul-Sp1Uqp"
      },
      "source": [
        " **5.2 Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tvZHqmY4965",
        "outputId": "6fd85e65-7753-4122-aa44-2c7f04334f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 5, 100)            455200    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 256)              234496    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4551)              1169607   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,859,303\n",
            "Trainable params: 1,859,303\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/300\n",
            "327/327 - 8s - loss: 5.5667 - accuracy: 0.1013 - 8s/epoch - 24ms/step\n",
            "Epoch 2/300\n",
            "327/327 - 5s - loss: 4.5037 - accuracy: 0.2026 - 5s/epoch - 14ms/step\n",
            "Epoch 3/300\n",
            "327/327 - 4s - loss: 4.0139 - accuracy: 0.2453 - 4s/epoch - 14ms/step\n",
            "Epoch 4/300\n",
            "327/327 - 4s - loss: 3.6733 - accuracy: 0.2785 - 4s/epoch - 14ms/step\n",
            "Epoch 5/300\n",
            "327/327 - 4s - loss: 3.4041 - accuracy: 0.3048 - 4s/epoch - 14ms/step\n",
            "Epoch 6/300\n",
            "327/327 - 4s - loss: 3.1808 - accuracy: 0.3294 - 4s/epoch - 14ms/step\n",
            "Epoch 7/300\n",
            "327/327 - 4s - loss: 2.9964 - accuracy: 0.3517 - 4s/epoch - 14ms/step\n",
            "Epoch 8/300\n",
            "327/327 - 4s - loss: 2.8348 - accuracy: 0.3741 - 4s/epoch - 14ms/step\n",
            "Epoch 9/300\n",
            "327/327 - 4s - loss: 2.7002 - accuracy: 0.3944 - 4s/epoch - 14ms/step\n",
            "Epoch 10/300\n",
            "327/327 - 4s - loss: 2.5893 - accuracy: 0.4111 - 4s/epoch - 14ms/step\n",
            "Epoch 11/300\n",
            "327/327 - 4s - loss: 2.4862 - accuracy: 0.4266 - 4s/epoch - 14ms/step\n",
            "Epoch 12/300\n",
            "327/327 - 4s - loss: 2.3942 - accuracy: 0.4429 - 4s/epoch - 14ms/step\n",
            "Epoch 13/300\n",
            "327/327 - 4s - loss: 2.3200 - accuracy: 0.4558 - 4s/epoch - 14ms/step\n",
            "Epoch 14/300\n",
            "327/327 - 4s - loss: 2.2486 - accuracy: 0.4680 - 4s/epoch - 14ms/step\n",
            "Epoch 15/300\n",
            "327/327 - 4s - loss: 2.1834 - accuracy: 0.4805 - 4s/epoch - 14ms/step\n",
            "Epoch 16/300\n",
            "327/327 - 4s - loss: 2.1240 - accuracy: 0.4904 - 4s/epoch - 14ms/step\n",
            "Epoch 17/300\n",
            "327/327 - 4s - loss: 2.0702 - accuracy: 0.5011 - 4s/epoch - 14ms/step\n",
            "Epoch 18/300\n",
            "327/327 - 4s - loss: 2.0221 - accuracy: 0.5101 - 4s/epoch - 14ms/step\n",
            "Epoch 19/300\n",
            "327/327 - 4s - loss: 1.9755 - accuracy: 0.5188 - 4s/epoch - 14ms/step\n",
            "Epoch 20/300\n",
            "327/327 - 4s - loss: 1.9332 - accuracy: 0.5267 - 4s/epoch - 14ms/step\n",
            "Epoch 21/300\n",
            "327/327 - 4s - loss: 1.8947 - accuracy: 0.5340 - 4s/epoch - 14ms/step\n",
            "Epoch 22/300\n",
            "327/327 - 4s - loss: 1.8574 - accuracy: 0.5414 - 4s/epoch - 14ms/step\n",
            "Epoch 23/300\n",
            "327/327 - 4s - loss: 1.8382 - accuracy: 0.5443 - 4s/epoch - 14ms/step\n",
            "Epoch 24/300\n",
            "327/327 - 4s - loss: 1.7944 - accuracy: 0.5548 - 4s/epoch - 14ms/step\n",
            "Epoch 25/300\n",
            "327/327 - 4s - loss: 1.7687 - accuracy: 0.5588 - 4s/epoch - 14ms/step\n",
            "Epoch 26/300\n",
            "327/327 - 4s - loss: 1.7390 - accuracy: 0.5645 - 4s/epoch - 14ms/step\n",
            "Epoch 27/300\n",
            "327/327 - 4s - loss: 1.7117 - accuracy: 0.5700 - 4s/epoch - 14ms/step\n",
            "Epoch 28/300\n",
            "327/327 - 4s - loss: 1.6948 - accuracy: 0.5739 - 4s/epoch - 14ms/step\n",
            "Epoch 29/300\n",
            "327/327 - 4s - loss: 1.6675 - accuracy: 0.5777 - 4s/epoch - 14ms/step\n",
            "Epoch 30/300\n",
            "327/327 - 4s - loss: 1.6467 - accuracy: 0.5822 - 4s/epoch - 14ms/step\n",
            "Epoch 31/300\n",
            "327/327 - 4s - loss: 1.6272 - accuracy: 0.5870 - 4s/epoch - 14ms/step\n",
            "Epoch 32/300\n",
            "327/327 - 4s - loss: 1.6055 - accuracy: 0.5912 - 4s/epoch - 14ms/step\n",
            "Epoch 33/300\n",
            "327/327 - 4s - loss: 1.5893 - accuracy: 0.5938 - 4s/epoch - 14ms/step\n",
            "Epoch 34/300\n",
            "327/327 - 4s - loss: 1.5690 - accuracy: 0.5980 - 4s/epoch - 14ms/step\n",
            "Epoch 35/300\n",
            "327/327 - 4s - loss: 1.5550 - accuracy: 0.6013 - 4s/epoch - 14ms/step\n",
            "Epoch 36/300\n",
            "327/327 - 5s - loss: 1.5375 - accuracy: 0.6047 - 5s/epoch - 14ms/step\n",
            "Epoch 37/300\n",
            "327/327 - 4s - loss: 1.5298 - accuracy: 0.6053 - 4s/epoch - 14ms/step\n",
            "Epoch 38/300\n",
            "327/327 - 4s - loss: 1.5137 - accuracy: 0.6080 - 4s/epoch - 14ms/step\n",
            "Epoch 39/300\n",
            "327/327 - 4s - loss: 1.5161 - accuracy: 0.6076 - 4s/epoch - 14ms/step\n",
            "Epoch 40/300\n",
            "327/327 - 4s - loss: 1.4916 - accuracy: 0.6126 - 4s/epoch - 14ms/step\n",
            "Epoch 41/300\n",
            "327/327 - 4s - loss: 1.4758 - accuracy: 0.6157 - 4s/epoch - 14ms/step\n",
            "Epoch 42/300\n",
            "327/327 - 4s - loss: 1.4639 - accuracy: 0.6189 - 4s/epoch - 14ms/step\n",
            "Epoch 43/300\n",
            "327/327 - 4s - loss: 1.4592 - accuracy: 0.6191 - 4s/epoch - 14ms/step\n",
            "Epoch 44/300\n",
            "327/327 - 4s - loss: 1.4462 - accuracy: 0.6213 - 4s/epoch - 14ms/step\n",
            "Epoch 45/300\n",
            "327/327 - 4s - loss: 1.4359 - accuracy: 0.6242 - 4s/epoch - 14ms/step\n",
            "Epoch 46/300\n",
            "327/327 - 4s - loss: 1.4294 - accuracy: 0.6245 - 4s/epoch - 14ms/step\n",
            "Epoch 47/300\n",
            "327/327 - 4s - loss: 1.4193 - accuracy: 0.6270 - 4s/epoch - 14ms/step\n",
            "Epoch 48/300\n",
            "327/327 - 4s - loss: 1.4068 - accuracy: 0.6284 - 4s/epoch - 14ms/step\n",
            "Epoch 49/300\n",
            "327/327 - 4s - loss: 1.3986 - accuracy: 0.6302 - 4s/epoch - 14ms/step\n",
            "Epoch 50/300\n",
            "327/327 - 4s - loss: 1.3894 - accuracy: 0.6313 - 4s/epoch - 14ms/step\n",
            "Epoch 51/300\n",
            "327/327 - 4s - loss: 1.3845 - accuracy: 0.6321 - 4s/epoch - 14ms/step\n",
            "Epoch 52/300\n",
            "327/327 - 5s - loss: 1.3788 - accuracy: 0.6341 - 5s/epoch - 14ms/step\n",
            "Epoch 53/300\n",
            "327/327 - 4s - loss: 1.3850 - accuracy: 0.6324 - 4s/epoch - 14ms/step\n",
            "Epoch 54/300\n",
            "327/327 - 4s - loss: 1.3671 - accuracy: 0.6359 - 4s/epoch - 14ms/step\n",
            "Epoch 55/300\n",
            "327/327 - 4s - loss: 1.3636 - accuracy: 0.6362 - 4s/epoch - 14ms/step\n",
            "Epoch 56/300\n",
            "327/327 - 5s - loss: 1.3546 - accuracy: 0.6380 - 5s/epoch - 14ms/step\n",
            "Epoch 57/300\n",
            "327/327 - 4s - loss: 1.3547 - accuracy: 0.6373 - 4s/epoch - 14ms/step\n",
            "Epoch 58/300\n",
            "327/327 - 4s - loss: 1.3430 - accuracy: 0.6395 - 4s/epoch - 14ms/step\n",
            "Epoch 59/300\n",
            "327/327 - 4s - loss: 1.3377 - accuracy: 0.6410 - 4s/epoch - 14ms/step\n",
            "Epoch 60/300\n",
            "327/327 - 4s - loss: 1.3344 - accuracy: 0.6405 - 4s/epoch - 14ms/step\n",
            "Epoch 61/300\n",
            "327/327 - 4s - loss: 1.3260 - accuracy: 0.6432 - 4s/epoch - 14ms/step\n",
            "Epoch 62/300\n",
            "327/327 - 4s - loss: 1.3211 - accuracy: 0.6426 - 4s/epoch - 14ms/step\n",
            "Epoch 63/300\n",
            "327/327 - 4s - loss: 1.3170 - accuracy: 0.6434 - 4s/epoch - 14ms/step\n",
            "Epoch 64/300\n",
            "327/327 - 4s - loss: 1.3194 - accuracy: 0.6432 - 4s/epoch - 14ms/step\n",
            "Epoch 65/300\n",
            "327/327 - 4s - loss: 1.3105 - accuracy: 0.6448 - 4s/epoch - 14ms/step\n",
            "Epoch 66/300\n",
            "327/327 - 4s - loss: 1.3104 - accuracy: 0.6446 - 4s/epoch - 14ms/step\n",
            "Epoch 67/300\n",
            "327/327 - 4s - loss: 1.3029 - accuracy: 0.6460 - 4s/epoch - 14ms/step\n",
            "Epoch 68/300\n",
            "327/327 - 4s - loss: 1.3019 - accuracy: 0.6454 - 4s/epoch - 14ms/step\n",
            "Epoch 69/300\n",
            "327/327 - 5s - loss: 1.2929 - accuracy: 0.6466 - 5s/epoch - 14ms/step\n",
            "Epoch 70/300\n",
            "327/327 - 4s - loss: 1.2956 - accuracy: 0.6469 - 4s/epoch - 14ms/step\n",
            "Epoch 71/300\n",
            "327/327 - 4s - loss: 1.2845 - accuracy: 0.6484 - 4s/epoch - 14ms/step\n",
            "Epoch 72/300\n",
            "327/327 - 4s - loss: 1.2817 - accuracy: 0.6494 - 4s/epoch - 14ms/step\n",
            "Epoch 73/300\n",
            "327/327 - 4s - loss: 1.2833 - accuracy: 0.6494 - 4s/epoch - 14ms/step\n",
            "Epoch 74/300\n",
            "327/327 - 4s - loss: 1.2764 - accuracy: 0.6498 - 4s/epoch - 14ms/step\n",
            "Epoch 75/300\n",
            "327/327 - 4s - loss: 1.2742 - accuracy: 0.6493 - 4s/epoch - 14ms/step\n",
            "Epoch 76/300\n",
            "327/327 - 4s - loss: 1.2729 - accuracy: 0.6496 - 4s/epoch - 14ms/step\n",
            "Epoch 77/300\n",
            "327/327 - 4s - loss: 1.2692 - accuracy: 0.6507 - 4s/epoch - 14ms/step\n",
            "Epoch 78/300\n",
            "327/327 - 4s - loss: 1.2621 - accuracy: 0.6514 - 4s/epoch - 14ms/step\n",
            "Epoch 79/300\n",
            "327/327 - 4s - loss: 1.2664 - accuracy: 0.6512 - 4s/epoch - 14ms/step\n",
            "Epoch 80/300\n",
            "327/327 - 4s - loss: 1.2638 - accuracy: 0.6511 - 4s/epoch - 14ms/step\n",
            "Epoch 81/300\n",
            "327/327 - 4s - loss: 1.2580 - accuracy: 0.6525 - 4s/epoch - 14ms/step\n",
            "Epoch 82/300\n",
            "327/327 - 4s - loss: 1.2592 - accuracy: 0.6520 - 4s/epoch - 14ms/step\n",
            "Epoch 83/300\n",
            "327/327 - 4s - loss: 1.2545 - accuracy: 0.6523 - 4s/epoch - 14ms/step\n",
            "Epoch 84/300\n",
            "327/327 - 4s - loss: 1.2482 - accuracy: 0.6535 - 4s/epoch - 14ms/step\n",
            "Epoch 85/300\n",
            "327/327 - 4s - loss: 1.2484 - accuracy: 0.6518 - 4s/epoch - 14ms/step\n",
            "Epoch 86/300\n",
            "327/327 - 4s - loss: 1.2485 - accuracy: 0.6526 - 4s/epoch - 14ms/step\n",
            "Epoch 87/300\n",
            "327/327 - 4s - loss: 1.2488 - accuracy: 0.6531 - 4s/epoch - 14ms/step\n",
            "Epoch 88/300\n",
            "327/327 - 4s - loss: 1.2525 - accuracy: 0.6509 - 4s/epoch - 14ms/step\n",
            "Epoch 89/300\n",
            "327/327 - 4s - loss: 1.2484 - accuracy: 0.6536 - 4s/epoch - 14ms/step\n",
            "Epoch 90/300\n",
            "327/327 - 4s - loss: 1.2357 - accuracy: 0.6546 - 4s/epoch - 14ms/step\n",
            "Epoch 91/300\n",
            "327/327 - 4s - loss: 1.2371 - accuracy: 0.6540 - 4s/epoch - 14ms/step\n",
            "Epoch 92/300\n",
            "327/327 - 4s - loss: 1.2447 - accuracy: 0.6535 - 4s/epoch - 14ms/step\n",
            "Epoch 93/300\n",
            "327/327 - 4s - loss: 1.2362 - accuracy: 0.6542 - 4s/epoch - 14ms/step\n",
            "Epoch 94/300\n",
            "327/327 - 4s - loss: 1.2338 - accuracy: 0.6547 - 4s/epoch - 14ms/step\n",
            "Epoch 95/300\n",
            "327/327 - 4s - loss: 1.2290 - accuracy: 0.6543 - 4s/epoch - 14ms/step\n",
            "Epoch 96/300\n",
            "327/327 - 4s - loss: 1.2313 - accuracy: 0.6551 - 4s/epoch - 14ms/step\n",
            "Epoch 97/300\n",
            "327/327 - 4s - loss: 1.2269 - accuracy: 0.6557 - 4s/epoch - 14ms/step\n",
            "Epoch 98/300\n",
            "327/327 - 4s - loss: 1.2236 - accuracy: 0.6557 - 4s/epoch - 14ms/step\n",
            "Epoch 99/300\n",
            "327/327 - 4s - loss: 1.2220 - accuracy: 0.6554 - 4s/epoch - 14ms/step\n",
            "Epoch 100/300\n",
            "327/327 - 4s - loss: 1.2210 - accuracy: 0.6559 - 4s/epoch - 14ms/step\n",
            "Epoch 101/300\n",
            "327/327 - 4s - loss: 1.2224 - accuracy: 0.6548 - 4s/epoch - 14ms/step\n",
            "Epoch 102/300\n",
            "327/327 - 4s - loss: 1.2346 - accuracy: 0.6540 - 4s/epoch - 14ms/step\n",
            "Epoch 103/300\n",
            "327/327 - 4s - loss: 1.2245 - accuracy: 0.6549 - 4s/epoch - 14ms/step\n",
            "Epoch 104/300\n",
            "327/327 - 4s - loss: 1.2148 - accuracy: 0.6562 - 4s/epoch - 14ms/step\n",
            "Epoch 105/300\n",
            "327/327 - 4s - loss: 1.2185 - accuracy: 0.6556 - 4s/epoch - 14ms/step\n",
            "Epoch 106/300\n",
            "327/327 - 4s - loss: 1.2122 - accuracy: 0.6574 - 4s/epoch - 14ms/step\n",
            "Epoch 107/300\n",
            "327/327 - 4s - loss: 1.2127 - accuracy: 0.6566 - 4s/epoch - 14ms/step\n",
            "Epoch 108/300\n",
            "327/327 - 4s - loss: 1.2150 - accuracy: 0.6559 - 4s/epoch - 14ms/step\n",
            "Epoch 109/300\n",
            "327/327 - 4s - loss: 1.2158 - accuracy: 0.6567 - 4s/epoch - 14ms/step\n",
            "Epoch 110/300\n",
            "327/327 - 4s - loss: 1.2142 - accuracy: 0.6561 - 4s/epoch - 14ms/step\n",
            "Epoch 111/300\n",
            "327/327 - 4s - loss: 1.2112 - accuracy: 0.6566 - 4s/epoch - 14ms/step\n",
            "Epoch 112/300\n",
            "327/327 - 5s - loss: 1.2130 - accuracy: 0.6562 - 5s/epoch - 14ms/step\n",
            "Epoch 113/300\n",
            "327/327 - 4s - loss: 1.2107 - accuracy: 0.6564 - 4s/epoch - 14ms/step\n",
            "Epoch 114/300\n",
            "327/327 - 4s - loss: 1.2064 - accuracy: 0.6563 - 4s/epoch - 14ms/step\n",
            "Epoch 115/300\n",
            "327/327 - 4s - loss: 1.2062 - accuracy: 0.6574 - 4s/epoch - 14ms/step\n",
            "Epoch 116/300\n",
            "327/327 - 4s - loss: 1.2071 - accuracy: 0.6573 - 4s/epoch - 14ms/step\n",
            "Epoch 117/300\n",
            "327/327 - 5s - loss: 1.2076 - accuracy: 0.6567 - 5s/epoch - 14ms/step\n",
            "Epoch 118/300\n",
            "327/327 - 4s - loss: 1.2039 - accuracy: 0.6574 - 4s/epoch - 14ms/step\n",
            "Epoch 119/300\n",
            "327/327 - 4s - loss: 1.2101 - accuracy: 0.6569 - 4s/epoch - 14ms/step\n",
            "Epoch 120/300\n",
            "327/327 - 4s - loss: 1.2021 - accuracy: 0.6584 - 4s/epoch - 14ms/step\n",
            "Epoch 121/300\n",
            "327/327 - 4s - loss: 1.1965 - accuracy: 0.6568 - 4s/epoch - 14ms/step\n",
            "Epoch 122/300\n",
            "327/327 - 4s - loss: 1.2074 - accuracy: 0.6574 - 4s/epoch - 14ms/step\n",
            "Epoch 123/300\n",
            "327/327 - 4s - loss: 1.2069 - accuracy: 0.6562 - 4s/epoch - 14ms/step\n",
            "Epoch 124/300\n",
            "327/327 - 5s - loss: 1.2002 - accuracy: 0.6570 - 5s/epoch - 14ms/step\n",
            "Epoch 125/300\n",
            "327/327 - 4s - loss: 1.1963 - accuracy: 0.6579 - 4s/epoch - 14ms/step\n",
            "Epoch 126/300\n",
            "327/327 - 4s - loss: 1.2013 - accuracy: 0.6571 - 4s/epoch - 14ms/step\n",
            "Epoch 127/300\n",
            "327/327 - 4s - loss: 1.2017 - accuracy: 0.6572 - 4s/epoch - 14ms/step\n",
            "Epoch 128/300\n",
            "327/327 - 4s - loss: 1.1934 - accuracy: 0.6577 - 4s/epoch - 14ms/step\n",
            "Epoch 129/300\n",
            "327/327 - 4s - loss: 1.1915 - accuracy: 0.6585 - 4s/epoch - 14ms/step\n",
            "Epoch 130/300\n",
            "327/327 - 4s - loss: 1.1928 - accuracy: 0.6578 - 4s/epoch - 14ms/step\n",
            "Epoch 131/300\n",
            "327/327 - 4s - loss: 1.1893 - accuracy: 0.6573 - 4s/epoch - 14ms/step\n",
            "Epoch 132/300\n",
            "327/327 - 4s - loss: 1.1879 - accuracy: 0.6582 - 4s/epoch - 14ms/step\n",
            "Epoch 133/300\n",
            "327/327 - 4s - loss: 1.1915 - accuracy: 0.6580 - 4s/epoch - 14ms/step\n",
            "Epoch 134/300\n",
            "327/327 - 4s - loss: 1.1908 - accuracy: 0.6570 - 4s/epoch - 14ms/step\n",
            "Epoch 135/300\n",
            "327/327 - 4s - loss: 1.1963 - accuracy: 0.6574 - 4s/epoch - 14ms/step\n",
            "Epoch 136/300\n",
            "327/327 - 4s - loss: 1.1860 - accuracy: 0.6582 - 4s/epoch - 14ms/step\n",
            "Epoch 137/300\n",
            "327/327 - 4s - loss: 1.1954 - accuracy: 0.6573 - 4s/epoch - 14ms/step\n",
            "Epoch 138/300\n",
            "327/327 - 4s - loss: 1.1879 - accuracy: 0.6573 - 4s/epoch - 14ms/step\n",
            "Epoch 139/300\n",
            "327/327 - 4s - loss: 1.1889 - accuracy: 0.6582 - 4s/epoch - 14ms/step\n",
            "Epoch 140/300\n",
            "327/327 - 4s - loss: 1.1848 - accuracy: 0.6581 - 4s/epoch - 14ms/step\n",
            "Epoch 141/300\n",
            "327/327 - 4s - loss: 1.1895 - accuracy: 0.6572 - 4s/epoch - 14ms/step\n",
            "Epoch 142/300\n",
            "327/327 - 4s - loss: 1.1834 - accuracy: 0.6583 - 4s/epoch - 14ms/step\n",
            "Epoch 143/300\n",
            "327/327 - 4s - loss: 1.1886 - accuracy: 0.6571 - 4s/epoch - 14ms/step\n",
            "Epoch 144/300\n",
            "327/327 - 4s - loss: 1.1845 - accuracy: 0.6591 - 4s/epoch - 14ms/step\n",
            "Epoch 145/300\n",
            "327/327 - 4s - loss: 1.1878 - accuracy: 0.6575 - 4s/epoch - 14ms/step\n",
            "Epoch 146/300\n",
            "327/327 - 4s - loss: 1.1854 - accuracy: 0.6583 - 4s/epoch - 14ms/step\n",
            "Epoch 147/300\n",
            "327/327 - 4s - loss: 1.1823 - accuracy: 0.6579 - 4s/epoch - 14ms/step\n",
            "Epoch 148/300\n",
            "327/327 - 4s - loss: 1.1839 - accuracy: 0.6583 - 4s/epoch - 14ms/step\n",
            "Epoch 149/300\n",
            "327/327 - 4s - loss: 1.1828 - accuracy: 0.6579 - 4s/epoch - 14ms/step\n",
            "Epoch 150/300\n",
            "327/327 - 4s - loss: 1.1866 - accuracy: 0.6580 - 4s/epoch - 14ms/step\n",
            "Epoch 151/300\n",
            "327/327 - 4s - loss: 1.1849 - accuracy: 0.6582 - 4s/epoch - 14ms/step\n",
            "Epoch 152/300\n",
            "327/327 - 4s - loss: 1.1839 - accuracy: 0.6581 - 4s/epoch - 14ms/step\n",
            "Epoch 153/300\n",
            "327/327 - 4s - loss: 1.1811 - accuracy: 0.6587 - 4s/epoch - 14ms/step\n",
            "Epoch 154/300\n",
            "327/327 - 4s - loss: 1.1844 - accuracy: 0.6577 - 4s/epoch - 14ms/step\n",
            "Epoch 155/300\n",
            "327/327 - 4s - loss: 1.1783 - accuracy: 0.6586 - 4s/epoch - 14ms/step\n",
            "Epoch 156/300\n",
            "327/327 - 4s - loss: 1.1826 - accuracy: 0.6579 - 4s/epoch - 14ms/step\n",
            "Epoch 157/300\n",
            "327/327 - 4s - loss: 1.1837 - accuracy: 0.6582 - 4s/epoch - 14ms/step\n",
            "Epoch 158/300\n",
            "327/327 - 4s - loss: 1.1770 - accuracy: 0.6586 - 4s/epoch - 14ms/step\n",
            "Epoch 159/300\n",
            "327/327 - 4s - loss: 1.1774 - accuracy: 0.6580 - 4s/epoch - 14ms/step\n",
            "Epoch 160/300\n",
            "327/327 - 4s - loss: 1.1845 - accuracy: 0.6574 - 4s/epoch - 14ms/step\n",
            "Epoch 161/300\n",
            "327/327 - 4s - loss: 1.1786 - accuracy: 0.6582 - 4s/epoch - 14ms/step\n",
            "Epoch 162/300\n",
            "327/327 - 4s - loss: 1.1796 - accuracy: 0.6580 - 4s/epoch - 14ms/step\n",
            "Epoch 163/300\n",
            "327/327 - 4s - loss: 1.1765 - accuracy: 0.6577 - 4s/epoch - 14ms/step\n",
            "Epoch 164/300\n",
            "327/327 - 5s - loss: 1.1760 - accuracy: 0.6584 - 5s/epoch - 14ms/step\n",
            "Epoch 165/300\n",
            "327/327 - 4s - loss: 1.1747 - accuracy: 0.6591 - 4s/epoch - 14ms/step\n",
            "Epoch 166/300\n",
            "327/327 - 4s - loss: 1.1780 - accuracy: 0.6583 - 4s/epoch - 14ms/step\n",
            "Epoch 167/300\n",
            "327/327 - 4s - loss: 1.1777 - accuracy: 0.6586 - 4s/epoch - 14ms/step\n",
            "Epoch 168/300\n",
            "327/327 - 4s - loss: 1.1750 - accuracy: 0.6588 - 4s/epoch - 14ms/step\n",
            "Epoch 169/300\n",
            "327/327 - 4s - loss: 1.1757 - accuracy: 0.6577 - 4s/epoch - 14ms/step\n",
            "Epoch 170/300\n",
            "327/327 - 4s - loss: 1.1740 - accuracy: 0.6582 - 4s/epoch - 14ms/step\n",
            "Epoch 171/300\n",
            "327/327 - 4s - loss: 1.1772 - accuracy: 0.6586 - 4s/epoch - 14ms/step\n",
            "Epoch 172/300\n",
            "327/327 - 4s - loss: 1.1718 - accuracy: 0.6590 - 4s/epoch - 14ms/step\n",
            "Epoch 173/300\n",
            "327/327 - 4s - loss: 1.1783 - accuracy: 0.6581 - 4s/epoch - 14ms/step\n",
            "Epoch 174/300\n",
            "327/327 - 4s - loss: 1.1797 - accuracy: 0.6578 - 4s/epoch - 14ms/step\n",
            "Epoch 175/300\n",
            "327/327 - 4s - loss: 1.1773 - accuracy: 0.6585 - 4s/epoch - 14ms/step\n",
            "Epoch 176/300\n",
            "327/327 - 4s - loss: 1.1759 - accuracy: 0.6584 - 4s/epoch - 14ms/step\n",
            "Epoch 177/300\n",
            "327/327 - 4s - loss: 1.1732 - accuracy: 0.6581 - 4s/epoch - 14ms/step\n",
            "Epoch 178/300\n",
            "327/327 - 4s - loss: 1.1714 - accuracy: 0.6581 - 4s/epoch - 14ms/step\n",
            "Epoch 179/300\n",
            "327/327 - 4s - loss: 1.1689 - accuracy: 0.6584 - 4s/epoch - 14ms/step\n",
            "Epoch 180/300\n",
            "327/327 - 4s - loss: 1.1659 - accuracy: 0.6592 - 4s/epoch - 14ms/step\n",
            "Epoch 181/300\n",
            "327/327 - 4s - loss: 1.1677 - accuracy: 0.6588 - 4s/epoch - 14ms/step\n",
            "Epoch 182/300\n",
            "327/327 - 4s - loss: 1.1672 - accuracy: 0.6592 - 4s/epoch - 14ms/step\n",
            "Epoch 183/300\n",
            "327/327 - 4s - loss: 1.1750 - accuracy: 0.6570 - 4s/epoch - 14ms/step\n",
            "Epoch 184/300\n",
            "327/327 - 5s - loss: 1.1691 - accuracy: 0.6593 - 5s/epoch - 14ms/step\n",
            "Epoch 185/300\n",
            "327/327 - 5s - loss: 1.1702 - accuracy: 0.6581 - 5s/epoch - 14ms/step\n",
            "Epoch 186/300\n",
            "327/327 - 5s - loss: 1.1705 - accuracy: 0.6593 - 5s/epoch - 14ms/step\n",
            "Epoch 187/300\n",
            "327/327 - 4s - loss: 1.1658 - accuracy: 0.6591 - 4s/epoch - 14ms/step\n",
            "Epoch 188/300\n",
            "327/327 - 4s - loss: 1.1680 - accuracy: 0.6579 - 4s/epoch - 14ms/step\n",
            "Epoch 189/300\n",
            "327/327 - 4s - loss: 1.1671 - accuracy: 0.6585 - 4s/epoch - 14ms/step\n",
            "Epoch 190/300\n",
            "327/327 - 4s - loss: 1.1685 - accuracy: 0.6583 - 4s/epoch - 14ms/step\n",
            "Epoch 191/300\n",
            "327/327 - 4s - loss: 1.1661 - accuracy: 0.6583 - 4s/epoch - 14ms/step\n",
            "Epoch 192/300\n",
            "327/327 - 4s - loss: 1.1708 - accuracy: 0.6579 - 4s/epoch - 14ms/step\n",
            "Epoch 193/300\n",
            "327/327 - 4s - loss: 1.1672 - accuracy: 0.6589 - 4s/epoch - 14ms/step\n",
            "Epoch 194/300\n",
            "327/327 - 4s - loss: 1.1691 - accuracy: 0.6583 - 4s/epoch - 14ms/step\n",
            "Epoch 195/300\n",
            "327/327 - 4s - loss: 1.1726 - accuracy: 0.6585 - 4s/epoch - 14ms/step\n",
            "Epoch 196/300\n",
            "327/327 - 5s - loss: 1.1682 - accuracy: 0.6586 - 5s/epoch - 14ms/step\n",
            "Epoch 197/300\n",
            "327/327 - 4s - loss: 1.1685 - accuracy: 0.6586 - 4s/epoch - 14ms/step\n",
            "Epoch 198/300\n",
            "327/327 - 5s - loss: 1.1656 - accuracy: 0.6588 - 5s/epoch - 14ms/step\n",
            "Epoch 199/300\n",
            "327/327 - 4s - loss: 1.1643 - accuracy: 0.6593 - 4s/epoch - 14ms/step\n",
            "Epoch 200/300\n",
            "327/327 - 4s - loss: 1.1632 - accuracy: 0.6583 - 4s/epoch - 14ms/step\n",
            "Epoch 201/300\n",
            "327/327 - 4s - loss: 1.1668 - accuracy: 0.6587 - 4s/epoch - 14ms/step\n",
            "Epoch 202/300\n",
            "327/327 - 4s - loss: 1.1639 - accuracy: 0.6588 - 4s/epoch - 14ms/step\n",
            "Epoch 203/300\n",
            "327/327 - 4s - loss: 1.1613 - accuracy: 0.6587 - 4s/epoch - 14ms/step\n",
            "Epoch 204/300\n",
            "327/327 - 4s - loss: 1.1645 - accuracy: 0.6588 - 4s/epoch - 14ms/step\n",
            "Epoch 205/300\n",
            "327/327 - 4s - loss: 1.1666 - accuracy: 0.6587 - 4s/epoch - 14ms/step\n",
            "Epoch 206/300\n",
            "327/327 - 4s - loss: 1.1665 - accuracy: 0.6588 - 4s/epoch - 14ms/step\n",
            "Epoch 207/300\n",
            "327/327 - 4s - loss: 1.1596 - accuracy: 0.6588 - 4s/epoch - 14ms/step\n",
            "Epoch 208/300\n",
            "327/327 - 4s - loss: 1.1631 - accuracy: 0.6586 - 4s/epoch - 14ms/step\n",
            "Epoch 209/300\n",
            "327/327 - 4s - loss: 1.1641 - accuracy: 0.6589 - 4s/epoch - 14ms/step\n",
            "Epoch 210/300\n",
            "327/327 - 4s - loss: 1.1595 - accuracy: 0.6593 - 4s/epoch - 14ms/step\n",
            "Epoch 211/300\n",
            "327/327 - 4s - loss: 1.1634 - accuracy: 0.6578 - 4s/epoch - 14ms/step\n",
            "Epoch 212/300\n",
            "327/327 - 4s - loss: 1.1630 - accuracy: 0.6592 - 4s/epoch - 14ms/step\n",
            "Epoch 213/300\n",
            "327/327 - 4s - loss: 1.1619 - accuracy: 0.6592 - 4s/epoch - 14ms/step\n",
            "Epoch 214/300\n",
            "327/327 - 4s - loss: 1.1618 - accuracy: 0.6577 - 4s/epoch - 14ms/step\n",
            "Epoch 215/300\n",
            "327/327 - 4s - loss: 1.1652 - accuracy: 0.6586 - 4s/epoch - 14ms/step\n",
            "Epoch 216/300\n",
            "327/327 - 4s - loss: 1.1585 - accuracy: 0.6588 - 4s/epoch - 14ms/step\n",
            "Epoch 217/300\n",
            "327/327 - 4s - loss: 1.1595 - accuracy: 0.6588 - 4s/epoch - 14ms/step\n",
            "Epoch 218/300\n",
            "327/327 - 4s - loss: 1.1600 - accuracy: 0.6590 - 4s/epoch - 14ms/step\n",
            "Epoch 219/300\n",
            "327/327 - 4s - loss: 1.1575 - accuracy: 0.6592 - 4s/epoch - 14ms/step\n",
            "Epoch 220/300\n",
            "327/327 - 4s - loss: 1.1609 - accuracy: 0.6584 - 4s/epoch - 14ms/step\n",
            "Epoch 221/300\n",
            "327/327 - 4s - loss: 1.1658 - accuracy: 0.6586 - 4s/epoch - 14ms/step\n",
            "Epoch 222/300\n",
            "327/327 - 4s - loss: 1.1620 - accuracy: 0.6595 - 4s/epoch - 14ms/step\n",
            "Epoch 223/300\n",
            "327/327 - 4s - loss: 1.1639 - accuracy: 0.6586 - 4s/epoch - 14ms/step\n",
            "Epoch 224/300\n",
            "327/327 - 4s - loss: 1.1638 - accuracy: 0.6582 - 4s/epoch - 14ms/step\n",
            "Epoch 225/300\n",
            "327/327 - 4s - loss: 1.1659 - accuracy: 0.6583 - 4s/epoch - 14ms/step\n",
            "Epoch 226/300\n",
            "327/327 - 4s - loss: 1.1605 - accuracy: 0.6587 - 4s/epoch - 14ms/step\n",
            "Epoch 227/300\n",
            "327/327 - 4s - loss: 1.1626 - accuracy: 0.6584 - 4s/epoch - 14ms/step\n",
            "Epoch 228/300\n",
            "327/327 - 4s - loss: 1.1552 - accuracy: 0.6592 - 4s/epoch - 14ms/step\n",
            "Epoch 229/300\n",
            "327/327 - 4s - loss: 1.1558 - accuracy: 0.6593 - 4s/epoch - 14ms/step\n",
            "Epoch 230/300\n",
            "327/327 - 4s - loss: 1.1556 - accuracy: 0.6591 - 4s/epoch - 14ms/step\n",
            "Epoch 231/300\n",
            "327/327 - 4s - loss: 1.1561 - accuracy: 0.6591 - 4s/epoch - 14ms/step\n",
            "Epoch 232/300\n",
            "327/327 - 4s - loss: 1.1682 - accuracy: 0.6587 - 4s/epoch - 14ms/step\n",
            "Epoch 233/300\n",
            "327/327 - 4s - loss: 1.1559 - accuracy: 0.6590 - 4s/epoch - 14ms/step\n",
            "Epoch 234/300\n",
            "327/327 - 4s - loss: 1.1567 - accuracy: 0.6591 - 4s/epoch - 14ms/step\n",
            "Epoch 235/300\n",
            "327/327 - 4s - loss: 1.1573 - accuracy: 0.6578 - 4s/epoch - 14ms/step\n",
            "Epoch 236/300\n",
            "327/327 - 4s - loss: 1.1590 - accuracy: 0.6591 - 4s/epoch - 14ms/step\n",
            "Epoch 237/300\n",
            "327/327 - 4s - loss: 1.1606 - accuracy: 0.6594 - 4s/epoch - 14ms/step\n",
            "Epoch 238/300\n",
            "327/327 - 4s - loss: 1.1556 - accuracy: 0.6592 - 4s/epoch - 14ms/step\n",
            "Epoch 239/300\n",
            "327/327 - 4s - loss: 1.1599 - accuracy: 0.6584 - 4s/epoch - 14ms/step\n",
            "Epoch 240/300\n",
            "327/327 - 4s - loss: 1.1540 - accuracy: 0.6585 - 4s/epoch - 14ms/step\n",
            "Epoch 241/300\n",
            "327/327 - 4s - loss: 1.1537 - accuracy: 0.6594 - 4s/epoch - 14ms/step\n",
            "Epoch 242/300\n",
            "327/327 - 4s - loss: 1.1566 - accuracy: 0.6582 - 4s/epoch - 14ms/step\n",
            "Epoch 243/300\n",
            "327/327 - 4s - loss: 1.1590 - accuracy: 0.6596 - 4s/epoch - 14ms/step\n",
            "Epoch 244/300\n",
            "327/327 - 4s - loss: 1.1587 - accuracy: 0.6584 - 4s/epoch - 14ms/step\n",
            "Epoch 245/300\n",
            "327/327 - 4s - loss: 1.1582 - accuracy: 0.6586 - 4s/epoch - 14ms/step\n",
            "Epoch 246/300\n",
            "327/327 - 4s - loss: 1.1591 - accuracy: 0.6593 - 4s/epoch - 14ms/step\n",
            "Epoch 247/300\n",
            "327/327 - 4s - loss: 1.1549 - accuracy: 0.6597 - 4s/epoch - 14ms/step\n",
            "Epoch 248/300\n",
            "327/327 - 4s - loss: 1.1553 - accuracy: 0.6587 - 4s/epoch - 14ms/step\n",
            "Epoch 249/300\n",
            "327/327 - 4s - loss: 1.1570 - accuracy: 0.6585 - 4s/epoch - 14ms/step\n",
            "Epoch 250/300\n",
            "327/327 - 4s - loss: 1.1618 - accuracy: 0.6587 - 4s/epoch - 14ms/step\n",
            "Epoch 251/300\n",
            "327/327 - 4s - loss: 1.1546 - accuracy: 0.6591 - 4s/epoch - 14ms/step\n",
            "Epoch 252/300\n",
            "327/327 - 4s - loss: 1.1549 - accuracy: 0.6590 - 4s/epoch - 14ms/step\n",
            "Epoch 253/300\n",
            "327/327 - 4s - loss: 1.1539 - accuracy: 0.6597 - 4s/epoch - 14ms/step\n",
            "Epoch 254/300\n",
            "327/327 - 4s - loss: 1.1538 - accuracy: 0.6577 - 4s/epoch - 14ms/step\n",
            "Epoch 255/300\n",
            "327/327 - 4s - loss: 1.1594 - accuracy: 0.6591 - 4s/epoch - 14ms/step\n",
            "Epoch 256/300\n",
            "327/327 - 5s - loss: 1.1558 - accuracy: 0.6585 - 5s/epoch - 14ms/step\n",
            "Epoch 257/300\n",
            "327/327 - 4s - loss: 1.1665 - accuracy: 0.6578 - 4s/epoch - 14ms/step\n",
            "Epoch 258/300\n",
            "327/327 - 4s - loss: 1.1578 - accuracy: 0.6589 - 4s/epoch - 14ms/step\n",
            "Epoch 259/300\n",
            "327/327 - 4s - loss: 1.1540 - accuracy: 0.6594 - 4s/epoch - 14ms/step\n",
            "Epoch 260/300\n",
            "327/327 - 4s - loss: 1.1554 - accuracy: 0.6590 - 4s/epoch - 14ms/step\n",
            "Epoch 261/300\n",
            "327/327 - 4s - loss: 1.1525 - accuracy: 0.6589 - 4s/epoch - 14ms/step\n",
            "Epoch 262/300\n",
            "327/327 - 4s - loss: 1.1521 - accuracy: 0.6595 - 4s/epoch - 14ms/step\n",
            "Epoch 263/300\n",
            "327/327 - 4s - loss: 1.1535 - accuracy: 0.6585 - 4s/epoch - 14ms/step\n",
            "Epoch 264/300\n",
            "327/327 - 4s - loss: 1.1539 - accuracy: 0.6590 - 4s/epoch - 14ms/step\n",
            "Epoch 265/300\n",
            "327/327 - 4s - loss: 1.1550 - accuracy: 0.6572 - 4s/epoch - 14ms/step\n",
            "Epoch 266/300\n",
            "327/327 - 4s - loss: 1.1540 - accuracy: 0.6585 - 4s/epoch - 14ms/step\n",
            "Epoch 267/300\n",
            "327/327 - 4s - loss: 1.1562 - accuracy: 0.6593 - 4s/epoch - 14ms/step\n",
            "Epoch 268/300\n",
            "327/327 - 5s - loss: 1.1577 - accuracy: 0.6588 - 5s/epoch - 14ms/step\n",
            "Epoch 269/300\n",
            "327/327 - 4s - loss: 1.1521 - accuracy: 0.6593 - 4s/epoch - 14ms/step\n",
            "Epoch 270/300\n",
            "327/327 - 4s - loss: 1.1541 - accuracy: 0.6586 - 4s/epoch - 14ms/step\n",
            "Epoch 271/300\n",
            "327/327 - 4s - loss: 1.1501 - accuracy: 0.6601 - 4s/epoch - 14ms/step\n",
            "Epoch 272/300\n",
            "327/327 - 4s - loss: 1.1507 - accuracy: 0.6591 - 4s/epoch - 14ms/step\n",
            "Epoch 273/300\n",
            "327/327 - 4s - loss: 1.1529 - accuracy: 0.6592 - 4s/epoch - 14ms/step\n",
            "Epoch 274/300\n",
            "327/327 - 4s - loss: 1.1553 - accuracy: 0.6592 - 4s/epoch - 14ms/step\n",
            "Epoch 275/300\n",
            "327/327 - 4s - loss: 1.1536 - accuracy: 0.6590 - 4s/epoch - 14ms/step\n",
            "Epoch 276/300\n",
            "327/327 - 4s - loss: 1.1519 - accuracy: 0.6593 - 4s/epoch - 14ms/step\n",
            "Epoch 277/300\n",
            "327/327 - 4s - loss: 1.1499 - accuracy: 0.6588 - 4s/epoch - 14ms/step\n",
            "Epoch 278/300\n",
            "327/327 - 4s - loss: 1.1484 - accuracy: 0.6591 - 4s/epoch - 14ms/step\n",
            "Epoch 279/300\n",
            "327/327 - 4s - loss: 1.1482 - accuracy: 0.6587 - 4s/epoch - 14ms/step\n",
            "Epoch 280/300\n",
            "327/327 - 4s - loss: 1.1584 - accuracy: 0.6577 - 4s/epoch - 14ms/step\n",
            "Epoch 281/300\n",
            "327/327 - 4s - loss: 1.1510 - accuracy: 0.6585 - 4s/epoch - 14ms/step\n",
            "Epoch 282/300\n",
            "327/327 - 4s - loss: 1.1536 - accuracy: 0.6584 - 4s/epoch - 14ms/step\n",
            "Epoch 283/300\n",
            "327/327 - 4s - loss: 1.1504 - accuracy: 0.6592 - 4s/epoch - 14ms/step\n",
            "Epoch 284/300\n",
            "327/327 - 4s - loss: 1.1537 - accuracy: 0.6590 - 4s/epoch - 14ms/step\n",
            "Epoch 285/300\n",
            "327/327 - 4s - loss: 1.1508 - accuracy: 0.6588 - 4s/epoch - 14ms/step\n",
            "Epoch 286/300\n",
            "327/327 - 4s - loss: 1.1499 - accuracy: 0.6600 - 4s/epoch - 14ms/step\n",
            "Epoch 287/300\n",
            "327/327 - 4s - loss: 1.1516 - accuracy: 0.6587 - 4s/epoch - 14ms/step\n",
            "Epoch 288/300\n",
            "327/327 - 4s - loss: 1.1477 - accuracy: 0.6586 - 4s/epoch - 14ms/step\n",
            "Epoch 289/300\n",
            "327/327 - 4s - loss: 1.1477 - accuracy: 0.6586 - 4s/epoch - 14ms/step\n",
            "Epoch 290/300\n",
            "327/327 - 4s - loss: 1.1488 - accuracy: 0.6595 - 4s/epoch - 14ms/step\n",
            "Epoch 291/300\n",
            "327/327 - 4s - loss: 1.1527 - accuracy: 0.6587 - 4s/epoch - 14ms/step\n",
            "Epoch 292/300\n",
            "327/327 - 4s - loss: 1.1527 - accuracy: 0.6587 - 4s/epoch - 14ms/step\n",
            "Epoch 293/300\n",
            "327/327 - 4s - loss: 1.1529 - accuracy: 0.6586 - 4s/epoch - 14ms/step\n",
            "Epoch 294/300\n",
            "327/327 - 4s - loss: 1.1522 - accuracy: 0.6591 - 4s/epoch - 14ms/step\n",
            "Epoch 295/300\n",
            "327/327 - 4s - loss: 1.1483 - accuracy: 0.6590 - 4s/epoch - 14ms/step\n",
            "Epoch 296/300\n",
            "327/327 - 4s - loss: 1.1472 - accuracy: 0.6587 - 4s/epoch - 14ms/step\n",
            "Epoch 297/300\n",
            "327/327 - 5s - loss: 1.1473 - accuracy: 0.6580 - 5s/epoch - 14ms/step\n",
            "Epoch 298/300\n",
            "327/327 - 4s - loss: 1.1500 - accuracy: 0.6587 - 4s/epoch - 14ms/step\n",
            "Epoch 299/300\n",
            "327/327 - 4s - loss: 1.1493 - accuracy: 0.6587 - 4s/epoch - 14ms/step\n",
            "Epoch 300/300\n",
            "327/327 - 4s - loss: 1.1511 - accuracy: 0.6587 - 4s/epoch - 14ms/step\n"
          ]
        }
      ],
      "source": [
        "# Get the untrained model\n",
        "epochs=50\n",
        "model = create_model(total_words, EMBEDDING_DIM, EMBEDDINGS_MATRIX, max_sequence_len)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(features, labels, epochs=300, verbose=2, batch_size = 512)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjrjvcI51nf1"
      },
      "source": [
        "# **6 Accuracy and Loss curves of trainned model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "CRd1pcFxhJgF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "14c18ec7-c89d-4ea5-b4d2-b29b0a8409c0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Take a look at the training curves of your model\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Final Results**: Getting 0.6585 accuracy with GLOVE EMBEDDINGS and predicting perfectly on random datasets."
      ],
      "metadata": {
        "id": "UEl9hMeHZl6A"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm8bOyTG1xFB"
      },
      "source": [
        "# **Download model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "3ZWGucWihLiK"
      },
      "outputs": [],
      "source": [
        "#download model\n",
        "def download_history():\n",
        "  import pickle\n",
        "  from google.colab import files\n",
        "\n",
        "  with open('history.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f)\n",
        "\n",
        "  files.download('history.pkl')\n",
        "\n",
        "#download_history()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hlVoy3_113a"
      },
      "source": [
        "# **Test model with new sentence**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5xOOjjoGhNoe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e19fe2bd-68ce-4b84-a75f-b5664e30bdeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yikes we can't do those times\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"yikes we can't\"\n",
        "\n",
        "next_words = 3\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\t# Convert the text into sequences\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\t# Pad the sequences\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len, padding='pre')\n",
        "\t# Get the probabilities of predicting a word\n",
        "\tpredicted = model.predict(token_list, verbose=0)\n",
        "\t# Choose the next word based on the maximum probability\n",
        "\tpredicted = np.argmax(predicted, axis=-1).item()\n",
        "\t# Get the actual word from the word index\n",
        "\toutput_word = tokenizer.index_word[predicted]\n",
        "\t# Append to the current text\n",
        "\tseed_text += \" \" + output_word\n",
        "\n",
        "print(seed_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sample Test Data**"
      ],
      "metadata": {
        "id": "0j1sV3VzZGji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seqs[:10]"
      ],
      "metadata": {
        "id": "hkx_4QE2m6pw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1771c05-59fd-4067-a959-dcf9f573b07f"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[\"hi i'm looking to book a\",\n",
              "  \"i'm looking to book a table\",\n",
              "  'looking to book a table for',\n",
              "  'to book a table for korean',\n",
              "  'book a table for korean fod'],\n",
              " ['somewhere in southern nyc maybe the',\n",
              "  'in southern nyc maybe the east',\n",
              "  'southern nyc maybe the east village'],\n",
              " [\"we don't want to sit at\",\n",
              "  \"don't want to sit at the\",\n",
              "  'want to sit at the bar',\n",
              "  'to sit at the bar but',\n",
              "  'sit at the bar but anywhere',\n",
              "  'at the bar but anywhere else',\n",
              "  'the bar but anywhere else is',\n",
              "  'bar but anywhere else is fine'],\n",
              " ['what times are available'],\n",
              " [\"yikes we can't do those times\"],\n",
              " ['let me check'],\n",
              " [\"great let's book that\"],\n",
              " [\"no that's it just book\"],\n",
              " ['hi i would like to see',\n",
              "  'i would like to see if',\n",
              "  'would like to see if the',\n",
              "  'like to see if the movie',\n",
              "  'to see if the movie what',\n",
              "  'see if the movie what men',\n",
              "  'if the movie what men want',\n",
              "  'the movie what men want is',\n",
              "  'movie what men want is playing',\n",
              "  'what men want is playing here'],\n",
              " ['yes for me and a friend',\n",
              "  'for me and a friend so',\n",
              "  'me and a friend so two',\n",
              "  'and a friend so two tickets',\n",
              "  'a friend so two tickets please']]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "NextWord_Generation_EDA_new.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}