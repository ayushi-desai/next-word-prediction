{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NextWord_Generation_FineTune_GPT2 (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b63ff5d5a771437ea0d2d0aba9af6df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fb16d3525874a4fa4c8fa4a66523abf",
              "IPY_MODEL_d94066ad1ced435e87d584c5b6415d8e",
              "IPY_MODEL_28033216b37d4527b1c78397a6913820"
            ],
            "layout": "IPY_MODEL_45dedd11c41f4cab8258e7c5e672aede"
          }
        },
        "5fb16d3525874a4fa4c8fa4a66523abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cceff91dfd674e72bcf71689fd954df0",
            "placeholder": "​",
            "style": "IPY_MODEL_f52aa13d284b48bcbbf3b7612cb50077",
            "value": "100%"
          }
        },
        "d94066ad1ced435e87d584c5b6415d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bdef42cc66f4ff0a2f2d3d0772efc65",
            "max": 64776,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f78cf36e9400452493f39e0c7d9791c5",
            "value": 64776
          }
        },
        "28033216b37d4527b1c78397a6913820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e829ac97d39c4be6a08860d38fad8cb7",
            "placeholder": "​",
            "style": "IPY_MODEL_c18be8ca8ddb450fa28c1404e1db1120",
            "value": " 64776/64776 [00:18&lt;00:00, 3705.04it/s]"
          }
        },
        "45dedd11c41f4cab8258e7c5e672aede": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cceff91dfd674e72bcf71689fd954df0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f52aa13d284b48bcbbf3b7612cb50077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3bdef42cc66f4ff0a2f2d3d0772efc65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f78cf36e9400452493f39e0c7d9791c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e829ac97d39c4be6a08860d38fad8cb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c18be8ca8ddb450fa28c1404e1db1120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2p_bqZM3WYu"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "1. Import Libraries\n",
        "2. Load Dataset\n",
        "3. Preprocessing and Exploring Text Data\n",
        "  \n",
        "  3.1 Text Cleaning\n",
        "  \n",
        "  3.2 Finding Word Count\n",
        "\n",
        "  3.3 Find and Replace Rare Words with \"Unknown\" Token\n",
        "\n",
        "4. Data Preparation\n",
        "\n",
        "  4.1 Prepare Sequences\n",
        "\n",
        "5. Download GPT-2\n",
         "\n",
        "6. Finetune GPT-2\n",
        "\n",
        "7. Load a trained model checkpoints\n"
        
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZoPOnsX8uPS"
      },
      "source": [
        "# 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_CCxOEI4iZK"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import re\n",
        "import random\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypl18CrLFmt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba5749d5-8607-4cbc-acb4-9c38028d3d90"
      },
      "source": [
        "# reproducing same results\n",
        "SEED = 2019\n",
        "\n",
        "# torch\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f595968e630>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_5gPvXxWjru"
      },
      "source": [
        "# 2. Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTcAv8MwCUep"
      },
      "source": [
        "# open text file and read in data\n",
        "with open(\"Dailog-dataset.dialogs_dataset\", \"rb\") as f:\n",
        "  dialogs = pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81_SXWZlE6Zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e06d553a-b398-4a96-885a-3bd9fc10920b"
      },
      "source": [
        "# number of text sequences\n",
        "len(dialogs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64776"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSyAzbttAqP2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575ee0a3-aa25-440d-f0c7-7bf5381b8bf7"
      },
      "source": [
        "# print 10 random dialogs\n",
        "random.sample(dialogs, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I'd like the Cappuccino\",\n",
              " 'sure anything also',\n",
              " 'Schedule a car for me tonight',\n",
              " \"I see, that's fine then\",\n",
              " 'Yeah pick up',\n",
              " 'Regular is just fine',\n",
              " 'Do you know how long it will take for the Uber driver to get here?',\n",
              " 'That sounds great',\n",
              " ' Just put in my name and it will go through',\n",
              " \" Let's do a table then\"]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGGTGRUDW9I3"
      },
      "source": [
        "# 3. Preprocessing and Exploring Text Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crvUl_ngM8sb"
      },
      "source": [
        "## 3.1 Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUuUKZgUFhkl"
      },
      "source": [
        "# text cleaning\n",
        "dialogs_clean = []\n",
        "\n",
        "for i in dialogs:\n",
        "  # remove everything except alphabets\n",
        "  i = re.sub(\"[^a-zA-Z' ]\", \"\", i)\n",
        "  # convert text to lowercase\n",
        "  i = i.lower()\n",
        "  # add cleaned text to the list\n",
        "  dialogs_clean.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgZwFK1eSjkN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ebe0445-992f-465d-de4d-2e5fc577e17c"
      },
      "source": [
        "random.sample(dialogs_clean, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the bruins game at the garden',\n",
              " 'yes a booth would be great',\n",
              " \"oh that's right just traditional crust then\",\n",
              " 'just forget about it',\n",
              " 'can i get an olive oil drizzle along with prosciutto',\n",
              " 'no we want to see imax',\n",
              " \"it's a honda civic\",\n",
              " 'let me send her a text and see what she would prefer',\n",
              " 'no just the one coffee',\n",
              " 'hi i would like to order pizza please']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYDzFQVvNA7_"
      },
      "source": [
        "\n",
        "## 3.2 Finding Word Count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1hrCYRp11UI"
      },
      "source": [
        "# get list of all the words\n",
        "all_words = \" \".join(dialogs_clean).split()\n",
        "\n",
        "words_dict = {}\n",
        "\n",
        "# add word-count pair to the dictionary\n",
        "for word in all_words:   \n",
        "  # check if the word is already in dictionary \n",
        "  if word in words_dict:\n",
        "    # increment count of word by 1 \n",
        "    words_dict[word] = words_dict[word] + 1\n",
        "  else:\n",
        "    # add the word to dictionary with count 1 \n",
        "    words_dict[word] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNxSGPubWaqA"
      },
      "source": [
        "# prepare a dataframe\n",
        "words_df = pd.DataFrame({'word':list(words_dict.keys()), 'count':list(words_dict.values())})\n",
        "\n",
        "# sort words by their count in increasing order\n",
        "words_df = words_df.sort_values(by = ['count'])\n",
        "\n",
        "# reset dataframe index\n",
        "words_df.reset_index(inplace = True, drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVPbPsSWo-Ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc186a99-ec21-4110-fc7c-dd492fc9b74b"
      },
      "source": [
        "# vocabulary size\n",
        "len(words_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11147"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTwmmOiEXBHt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "54a89fd9-981d-494c-fc26-e293c546146f"
      },
      "source": [
        "words_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          word  count\n",
              "0  uppermiddle      1\n",
              "1       shoots      1\n",
              "2        geesh      1\n",
              "3       andrea      1\n",
              "4      precice      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8aecff35-b928-40c2-aff2-25692a52f0ff\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>uppermiddle</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>shoots</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>geesh</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>andrea</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>precice</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8aecff35-b928-40c2-aff2-25692a52f0ff')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8aecff35-b928-40c2-aff2-25692a52f0ff button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8aecff35-b928-40c2-aff2-25692a52f0ff');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWJEto8TMPiq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "6e6b7556-7a52-4255-bb04-72cec7257695"
      },
      "source": [
        "words_df.tail()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      word  count\n",
              "11142  you  11909\n",
              "11143    a  13380\n",
              "11144   to  14000\n",
              "11145  the  15406\n",
              "11146    i  19654"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-97513fe1-f768-42c7-a15c-e137f0146b2d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11142</th>\n",
              "      <td>you</td>\n",
              "      <td>11909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11143</th>\n",
              "      <td>a</td>\n",
              "      <td>13380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11144</th>\n",
              "      <td>to</td>\n",
              "      <td>14000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11145</th>\n",
              "      <td>the</td>\n",
              "      <td>15406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11146</th>\n",
              "      <td>i</td>\n",
              "      <td>19654</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97513fe1-f768-42c7-a15c-e137f0146b2d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97513fe1-f768-42c7-a15c-e137f0146b2d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97513fe1-f768-42c7-a15c-e137f0146b2d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTcWd-pYFRob"
      },
      "source": [
        "## 3.3 Find and Replace Rare Words with \"Unknown\" Token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iC4ztG3XIP3"
      },
      "source": [
        "# user specified threshold value\n",
        "rare_thresh = 4\n",
        "\n",
        "# get percentage of rare words in the vocabulary\n",
        "rare_words_count = len(words_df[words_df['count'] < rare_thresh]['word'])\n",
        "total_words = len(words_df) \n",
        "rare_dist = rare_words_count / total_words\n",
        "\n",
        "# coverage percentage of rare words in the corpus\n",
        "rare_cover = words_df[words_df['count'] < rare_thresh]['count'].sum()/words_df['count'].sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "helYHQ4BXNK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11049eb7-a73d-4756-84a1-775b443cd443"
      },
      "source": [
        "print(f\"Rare words distribution in the vocabulary: {rare_dist*100:.2f}\")\n",
        "print(f\"Rare words coverage in the corpus: {rare_cover*100:.2f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rare words distribution in the vocabulary: 69.03\n",
            "Rare words coverage in the corpus: 2.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJhbRQllXQJk"
      },
      "source": [
        "# extract rare words in a list\n",
        "rare_words = words_df[words_df['count'] < rare_thresh]['word'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "178uBVztqTDa"
      },
      "source": [
        "Let's see the technique that we will use to replace the rare words/tokens in the dataset with a special token known as the unknown token (\"\\<unk\\>\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5tSChzyoOJT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd9b21b0-c11c-4cb5-c042-a5d9cb8e17a8"
      },
      "source": [
        "## example\n",
        "# specify rare words\n",
        "r_words = [\"day\", \"book\"]\n",
        "\n",
        "# build pattern\n",
        "pattern = \"\"\n",
        "for i in r_words:\n",
        "  pattern+= \"{}|\".format(i)\n",
        "\n",
        "print(pattern)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day|book|\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZAMqmwPowZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c82e0d-5f40-4437-eb8a-ae70009c371b"
      },
      "source": [
        "# removing the last element which is \"|\"\n",
        "pattern = pattern[:-1]\n",
        "print(pattern)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "day|book\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV1K1ibbo3XI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887ad3f3-1b16-4a0b-8529-1da8ebebc815"
      },
      "source": [
        "# replace the rare words with the <unk> token\n",
        "sents = [\"it has been a long day\", \"this book is a must read\"]\n",
        "\n",
        "for d in sents:\n",
        "  text = re.sub(pattern, \" <unk> \", d)\n",
        "  print(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it has been a long  <unk> \n",
            "this  <unk>  is a must read\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEn-L1_8YBjl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "b63ff5d5a771437ea0d2d0aba9af6df2",
            "5fb16d3525874a4fa4c8fa4a66523abf",
            "d94066ad1ced435e87d584c5b6415d8e",
            "28033216b37d4527b1c78397a6913820",
            "45dedd11c41f4cab8258e7c5e672aede",
            "cceff91dfd674e72bcf71689fd954df0",
            "f52aa13d284b48bcbbf3b7612cb50077",
            "3bdef42cc66f4ff0a2f2d3d0772efc65",
            "f78cf36e9400452493f39e0c7d9791c5",
            "e829ac97d39c4be6a08860d38fad8cb7",
            "c18be8ca8ddb450fa28c1404e1db1120"
          ]
        },
        "outputId": "97c82145-5ea8-4f0f-cb64-afb9103ca59a"
      },
      "source": [
        "# create a text pattern from the rare words, like \"word1 | word2 | word3...\"\n",
        "pattern = \"\"\n",
        "for i in rare_words:\n",
        "  pattern+= \" {} |\".format(i)\n",
        "\n",
        "# removing the last element which is \"|\"\n",
        "pattern = pattern[:-1]\n",
        "\n",
        "# empty list \n",
        "dialogs_clean_v2 = []\n",
        "\n",
        "# replace the rare words with the <unk> token\n",
        "for d in tqdm_notebook(dialogs_clean):\n",
        "  text = re.sub(pattern, \" <unk> \", d)\n",
        "  dialogs_clean_v2.append(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/64776 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b63ff5d5a771437ea0d2d0aba9af6df2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoQwO5FAZSP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6d8a5c7-8096-4c8f-d937-a4d3a0934cbe"
      },
      "source": [
        "dialogs_clean_v2[520:530]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['does it serve traditional chinese dessert',\n",
              " 'how much extra time to reach <unk> ',\n",
              " 'ok lets reserve a table for dinner at hakkasan',\n",
              " 'hello i need to get a car please',\n",
              " 'holiday inn <unk> parkconv <unk> convention center drive <unk> park il',\n",
              " 'bowling alley <unk> highway <unk> park il',\n",
              " 'what types of cars does uber have',\n",
              " \"what's the price difference\",\n",
              " 'ok get me the cheapest please',\n",
              " 'ok then get me the next level']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waTukoy1AbVT"
      },
      "source": [
        "# 4. Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SvIJQ0brBWW"
      },
      "source": [
        "## 4.1 Prepare Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5BYGcwBF7hX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "4cdd490b-7028-4dd3-b9f2-d0ed8f1fdb35"
      },
      "source": [
        "# capture length of all the sequences\n",
        "text_word_count = []\n",
        "for i in dialogs_clean_v2:\n",
        "  text_word_count.append(len(i.split()))\n",
        "        \n",
        "# plot the sequence lengths\n",
        "pd.Series(text_word_count).hist(bins = 30,range=(0,30))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f595572f8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw8F6bfwjBeo"
      },
      "source": [
        "# function to create sequences of equal length\n",
        "def create_seq(text, seq_len = 5):\n",
        "      \n",
        "  sequences = []    \n",
        "  \n",
        "  if len(text.split()) > seq_len:\n",
        "    for i in range(seq_len, len(text.split())):\n",
        "      # select sequence of tokens\n",
        "      seq = text.split()[i-seq_len:i+1]\n",
        "      # append sequence to the list\n",
        "      sequences.append(\" \".join(seq))\n",
        "\n",
        "    return sequences\n",
        "\n",
        "  else:\n",
        "    \n",
        "    return [text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0psJCgo9QtH"
      },
      "source": [
        "# create sequences of equal length\n",
        "seqs = [create_seq(i) for i in dialogs_clean_v2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCrf5t5vCI6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a7cbc6-4ece-455d-d8ac-7742506f9b65"
      },
      "source": [
        "seqs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[\"hi i'm looking to book a\",\n",
              "  \"i'm looking to book a table\",\n",
              "  'looking to book a table for',\n",
              "  'to book a table for korean',\n",
              "  'book a table for korean fod'],\n",
              " ['somewhere in southern nyc maybe the',\n",
              "  'in southern nyc maybe the east',\n",
              "  'southern nyc maybe the east village'],\n",
              " [\"we don't want to sit at\",\n",
              "  \"don't want to sit at the\",\n",
              "  'want to sit at the bar',\n",
              "  'to sit at the bar but',\n",
              "  'sit at the bar but anywhere',\n",
              "  'at the bar but anywhere else',\n",
              "  'the bar but anywhere else is',\n",
              "  'bar but anywhere else is fine'],\n",
              " ['what times are available'],\n",
              " [\"yikes we can't do those times\"],\n",
              " ['let me check'],\n",
              " [\"great let's book that\"],\n",
              " [\"no that's it just book\"],\n",
              " ['hi i would like to see',\n",
              "  'i would like to see if',\n",
              "  'would like to see if the',\n",
              "  'like to see if the movie',\n",
              "  'to see if the movie what',\n",
              "  'see if the movie what men',\n",
              "  'if the movie what men want',\n",
              "  'the movie what men want is',\n",
              "  'movie what men want is playing',\n",
              "  'what men want is playing here'],\n",
              " ['yes for me and a friend',\n",
              "  'for me and a friend so',\n",
              "  'me and a friend so two',\n",
              "  'and a friend so two tickets',\n",
              "  'a friend so two tickets please']]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4O3-S6PA78w"
      },
      "source": [
        "# merge list-of-lists into a single list\n",
        "seqs = sum(seqs, [])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwmBsxuqxPRq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c0b5dd3-103e-45b8-be6d-53adc3d237bf"
      },
      "source": [
        "seqs[:15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"hi i'm looking to book a\",\n",
              " \"i'm looking to book a table\",\n",
              " 'looking to book a table for',\n",
              " 'to book a table for korean',\n",
              " 'book a table for korean fod',\n",
              " 'somewhere in southern nyc maybe the',\n",
              " 'in southern nyc maybe the east',\n",
              " 'southern nyc maybe the east village',\n",
              " \"we don't want to sit at\",\n",
              " \"don't want to sit at the\",\n",
              " 'want to sit at the bar',\n",
              " 'to sit at the bar but',\n",
              " 'sit at the bar but anywhere',\n",
              " 'at the bar but anywhere else',\n",
              " 'the bar but anywhere else is']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNW5MIpTDufa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a46ce8a7-02fd-476f-9feb-42fedbefd49d"
      },
      "source": [
        "# count of sequences\n",
        "len(seqs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "205346"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0dppnffaEgG"
      },
      "source": [
        "# create input and target sequences (x and y)\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "for s in seqs:\n",
        "  x.append(\" \".join(s.split()[:-1]))\n",
        "  y.append(\" \".join(s.split()[1:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27XKPYgLwuOF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "206288cc-bc34-4045-f847-120559c349d5"
      },
      "source": [
        "x[0], y[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"hi i'm looking to book\", \"i'm looking to book a\")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVge-c6WHUx1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79d8895a-02ff-4630-92ec-ed685e3e82ce"
      },
      "source": [
        "x[88543], y[88543]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('to drive to several locations', 'drive to several locations do')"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzR5aG9wrZJ5"
      },
      "source": [
        "## 4.2 Create Token-Integer Mappings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSgaezAI60ht"
      },
      "source": [
        "# create integer-to-token mapping\n",
        "int2token = {}\n",
        "cnt = 1\n",
        "\n",
        "for w in set(\" \".join(dialogs_clean_v2).split()):\n",
        "  int2token[cnt] = w\n",
        "  cnt+= 1\n",
        "\n",
        "# create token-to-integer mapping\n",
        "token2int = {t: i for i, t in int2token.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5TSElOk_OQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a002661-22e0-40ad-b33b-afdd58f56db3"
      },
      "source": [
        "token2int[\"can\"], int2token[1127]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4363, 'jabos')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQOk80iBr51V"
      },
      "source": [
        "## 4.3 Split Data into Train and Validation Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn6a1aXvAcRl"
      },
      "source": [
        "# train-validation split\n",
        "# input sequences\n",
        "x_tr = x[:150000]\n",
        "x_val = x[150000:]\n",
        "\n",
        "# target sequences\n",
        "y_tr = y[:150000]\n",
        "y_val = y[150000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "yR6Yw7ft2YYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__JAFRJX8ujd",
        "outputId": "dd6fb751-28d5-4904-e98d-ecdc6242c84c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jun 27 20:49:35 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model\n",
        "* `1558M`: the \"extra large\", true model. Will not work if a K80/P4 GPU is attached to the notebook.\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n"
      ],
      "metadata": {
        "id": "YgLPS1EE03VL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "metadata": {
        "id": "MSTm28_u9Egc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c80f2e3-815c-43fe-e6b1-52b49072b197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 383Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:01, 576kit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 591Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [01:22, 6.06Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 580Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:01, 878kit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:01, 756kit/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mounting Google Drive**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CqfbXayPGCL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCnknqKD3Aro",
        "outputId": "7436186f-94fc-4466-ab4e-a7b7d4516ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Uploading Text File To be Trained **\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "MkVbx-69GLMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"Dailog-dataset.dialogs_dataset\""
      ],
      "metadata": {
        "id": "D7zpgBLq_ql4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "metadata": {
        "id": "f47j2eYt39uI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
      ],
      "metadata": {
        "id": "u5p1c3lQGZQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=100,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWVPi-Vh4gPO",
        "outputId": "4b45d094-7d4c-4690-8f50-6fea50785930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:04<00:00,  4.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 1135910 tokens\n",
            "Training...\n",
            "[10 | 27.63] loss=3.72 avg=3.72\n",
            "[20 | 49.42] loss=2.69 avg=3.20\n",
            "[30 | 71.60] loss=2.61 avg=3.00\n",
            "[40 | 94.21] loss=2.39 avg=2.85\n",
            "[50 | 117.32] loss=2.29 avg=2.73\n",
            "[60 | 140.48] loss=2.28 avg=2.66\n",
            "[70 | 163.35] loss=2.21 avg=2.59\n",
            "[80 | 186.23] loss=2.04 avg=2.52\n",
            "[90 | 209.28] loss=2.26 avg=2.49\n",
            "[100 | 232.30] loss=2.12 avg=2.45\n",
            "Saving checkpoint/run1/model-100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "metadata": {
        "id": "bQnMigX748FI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ],
      "metadata": {
        "id": "uRYGr6BtG4Yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "metadata": {
        "id": "LQ2F9LmZ57EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"774M\"\n",
        "\n",
        "gpt2.download_gpt2(model_name=model_name)"
      ],
      "metadata": {
        "id": "VrraJfFISrcq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e77890d-88ef-4d3d-89e2-d7c098bb9908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 525Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:01, 652kit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 317Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [08:27, 6.10Mit/s]\n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 302Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 2.10Mit [00:02, 1.04Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:01, 747kit/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.load_gpt2(sess, model_name=model_name)"
      ],
      "metadata": {
        "id": "KtkRjqhHSv8E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1671e31f-42d5-4a7c-b5e0-d782423de4df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pretrained model models/774M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/774M/model.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ],
      "metadata": {
        "id": "UWdo1DsVHBAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.generate(sess,\n",
        "              model_name=model_name,\n",
        "              prefix=\"yikes we can't do\",\n",
        "              length=10,\n",
        "              temperature=0.7,\n",
        "              top_p=0.9,\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "metadata": {
        "id": "T8k3Fbt3S2fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6b073cd-cad2-4cc1-dce6-cf627a920509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yikes we can't do it. It's that we don't have the\n",
            "====================\n",
            "yikes we can't do anything. I don't want to just see a\n",
            "====================\n",
            "yikes we can't do it without the help of our friends, and our\n",
            "====================\n",
            "yikes we can't do anything about it,\" he said.\n",
            "\n",
            "W\n",
            "====================\n",
            "yikes we can't do that, but we can make it happen.\n",
            "\n",
            "====================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "metadata": {
        "id": "UY0fpobA6Fut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c1d71f8-5107-41af-ac0f-32b9b7218798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint checkpoint/run1/model-100\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ],
      "metadata": {
        "id": "cqCAfMux6lK6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6807f7e-c677-458f-b4ef-1bbe50ebe41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dirty\n",
            "Dirty\n",
            "Dirty\n",
            "Dirty\n",
            "Dirty\n",
            "Dirty\n",
            "Dirty\n",
            "Dirty\n",
            "Dirty\n",
            "Dino hopped up on the sidewalk shortly after because he wanted to dorr\"r\"rAccording to the card, I'm thinking we should do something a bit more than therE I'm thinking we should go with a few StarbucksrF I'm thinking we should place an order at the nearest StarbucksrG I think we should go with a small Italian pizzarH I'd like to take a small pizza with sausage and green peppersrI I'd like to order a large and have a nice largerJ I'd like to order a medium with sausage and green peppersrK I'd like to order a large with mushroomsrL I'd like to order a large with mushroomsrM I'd like it to be a regular size, but I'd like to pick it uprN I'd like it to be largerO I'd like it to be small, but it's finerP I'd like it to be largerQ I'd like it to be small, but I'd like to pick it uprR\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000I need a pizza for dinnerrA\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000I need a large pizzarB\u0000\u0000\u0000\u0000I want a medium pizzarC\u0000\u0000\u0000\u0000I want a medium pizzarD\u0000\u0000\u0000I want a large pizzarE\u0000\u0000\u0000I want a large pizzarF\u0000\u0000\u0000I want a large pizzarG\u0000\u0000\u0000I want a larger pizzarH\u0000\u0000\u0000I want a medium pizzarI\u0000\u0000\u0000I want a large pizzarJ\u0000\u0000\u0000I want my own pizzarK\u0000\u0000\u0000I want a medium pizzarL\u0000\u0000\u0000I want a large pizzarM\u0000\u0000\u0000I want two pizzasrN\u0000\u0000\u0000I want two pepperoni pizzasrO\u0000\u0000\u0000I want two pepperoni pizzasrP\u0000\u0000\u0000I want two yellow pepperoni pizzasrQ\u0000\u0000\u0000I want two large pizzasrR\u0000\u0000\u0000I want two large pizzasrS\u0000\u0000\u0000I want two medium pizzasrT\u0000\u0000\u0000I want two large pizzasrU\u0000\u0000\u0000I want two medium pizzasrV\u0000\u0000\u0000I want two large pizzasrW\u0000\u0000\u0000I want two large pizzasrX\u0000\u0000\u0000\u0000I want two medium pizzasrY\u0000\u0000\u0000I want three pizzasrZ\u0000\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two large pizzasr\\\u0000\u0000I want two large pizzasr\\\u0000\u0000I want two large pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two large pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two large pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\\\u0000\u0000I want two medium pizzasr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=500,\n",
        "                      temperature=0.7,\n",
        "                      nsamples=100,\n",
        "                      batch_size=20\n",
        "                      )"
      ],
      "metadata": {
        "id": "IMDQfrvw6_QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# may have to run twice to get file to download\n",
        "files.download(gen_file)"
      ],
      "metadata": {
        "id": "7Zu_vMHg7G5C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5a185a18-5f75-41d8-84d7-133d809ef268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0436108d-11fe-4d9b-9f02-b259db34d854\", \"gpt2_gentext_20220627_213051.txt\", 167437)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
